#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–£–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
"""

import os
import json
import cv2
import numpy as np
from openai import OpenAI
from dataclasses import dataclass
from typing import List, Dict, Tuple, Optional
import logging
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class TranscriptMoment:
    """–í–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–µ –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞"""
    timestamp: float
    reason: str
    importance: float
    keywords: List[str]
    context: str
    screenshot_type: str  # "demo", "slide", "code", "diagram", "ui"

class SmartTranscriptExtractor:
    """–£–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key)
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–π
        self.demo_keywords = {
            "screen_share": ["–ø–æ–∫–∞–∂—É", "—Å–º–æ—Ç—Ä–∏—Ç–µ", "–≤–∏–¥–∏—Ç–µ", "–≤–æ—Ç –∑–¥–µ—Å—å", "–Ω–∞ —ç–∫—Ä–∞–Ω–µ", "–¥–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º"],
            "code": ["–∫–æ–¥", "—Ñ—É–Ω–∫—Ü–∏—è", "–º–µ—Ç–æ–¥", "–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è", "–∞–ª–≥–æ—Ä–∏—Ç–º", "–∫–ª–∞—Å—Å", "—Å–∫—Ä–∏–ø—Ç", "—Ñ–∞–π–ª"],
            "presentation": ["—Å–ª–∞–π–¥", "–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è", "—Å–ª–µ–¥—É—é—â–∏–π", "–≤–∏–¥–∏–º", "–ø–æ–∫–∞–∑–∞–Ω–æ", "–¥–∏–∞–≥—Ä–∞–º–º–∞"],
            "demo": ["–¥–µ–º–æ", "–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è", "–ø—Ä–∏–º–µ—Ä", "—Ä–∞–±–æ—Ç–∞–µ—Ç", "–∑–∞–ø—É—Å—Ç–∏–º", "–ø–æ—Å–º–æ—Ç—Ä–∏–º –∫–∞–∫"],
            "diagram": ["—Å—Ö–µ–º–∞", "–¥–∏–∞–≥—Ä–∞–º–º–∞", "—Å—Ç—Ä—É–∫—Ç—É—Ä–∞", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "–ø–æ—Ç–æ–∫", "–ø—Ä–æ—Ü–µ—Å—Å"],
            "ui": ["–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å", "–∫–Ω–æ–ø–∫–∞", "–º–µ–Ω—é", "—Ñ–æ—Ä–º–∞", "—Å—Ç—Ä–∞–Ω–∏—Ü–∞", "–æ–∫–Ω–æ", "—ç–ª–µ–º–µ–Ω—Ç"],
            "document": ["–¥–æ–∫—É–º–µ–Ω—Ç", "—Ñ–∞–π–ª", "—Ç–µ–∫—Å—Ç", "—Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ", "–ø—É–Ω–∫—Ç", "—Ä–∞–∑–¥–µ–ª"],
            "discussion": ["–æ–±—Å—É–∂–¥–∞–µ–º", "–º–Ω–µ–Ω–∏–µ", "–¥—É–º–∞—é", "—Å—á–∏—Ç–∞—é", "–ø—Ä–µ–¥–ª–∞–≥–∞—é", "–≤–æ–ø—Ä–æ—Å"]
        }
        
        # –¢—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        self.trigger_phrases = [
            r"–≤–æ—Ç\s+(–∑–¥–µ—Å—å|—Ç—É—Ç|—ç—Ç–æ)",
            r"—Å–º–æ—Ç—Ä–∏—Ç–µ\s+(–Ω–∞|—Å—é–¥–∞)",
            r"–≤–∏–¥–∏—Ç–µ\s+(—ç—Ç–æ|–∑–¥–µ—Å—å)",
            r"–ø–æ–∫–∞–∂—É\s+(–≤–∞–º|–∫–∞–∫)",
            r"–¥–∞–≤–∞–π—Ç–µ\s+–ø–æ—Å–º–æ—Ç—Ä–∏–º",
            r"–Ω–∞–ø—Ä–∏–º–µ—Ä\s+(–∑–¥–µ—Å—å|—ç—Ç–æ)",
            r"–ø–µ—Ä–µ—Ö–æ–¥–∏–º\s+–∫",
            r"—Å–ª–µ–¥—É—é—â–∏–π\s+(—Å–ª–∞–π–¥|–ø—É–Ω–∫—Ç|—Ä–∞–∑–¥–µ–ª)",
            r"–æ—Ç–∫—Ä—ã–≤–∞—é\s+(—Ñ–∞–π–ª|–¥–æ–∫—É–º–µ–Ω—Ç|–∫–æ–¥)",
            r"–∑–∞–ø—É—Å–∫–∞—é\s+(–ø—Ä–æ–≥—Ä–∞–º–º—É|—Å–∫—Ä–∏–ø—Ç)",
            r"–≤—ã–∑—ã–≤–∞—é\s+(—Ñ—É–Ω–∫—Ü–∏—é|–º–µ—Ç–æ–¥)",
            r"–Ω–∞–∂–∏–º–∞—é\s+(–∫–Ω–æ–ø–∫—É|—Å—Å—ã–ª–∫—É)"
        ]
    
    def extract_screenshots(self, video_path: str, output_dir: str, 
                           transcript_segments: List[Dict]) -> List[Tuple]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"""
        
        logger.info(f"üß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # –®–∞–≥ 1: –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏ –Ω–∞—Ö–æ–¥–∏–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
        key_moments = self.analyze_transcript_for_moments(transcript_segments)
        
        logger.info(f"üìç –ù–∞–π–¥–µ–Ω–æ {len(key_moments)} –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤")
        
        # –®–∞–≥ 2: –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –±–ª–∏–∑–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        optimized_moments = self.optimize_moments(key_moments)
        
        logger.info(f"‚ú® –ü–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏: {len(optimized_moments)} –º–æ–º–µ–Ω—Ç–æ–≤")
        
        # –®–∞–≥ 3: –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã
        screenshots = self.extract_targeted_screenshots(
            video_path, output_dir, optimized_moments, transcript_segments
        )
        
        logger.info(f"üì∏ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(screenshots)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
        
        return screenshots
    
    def analyze_transcript_for_moments(self, transcript_segments: List[Dict]) -> List[TranscriptMoment]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∏ –Ω–∞—Ö–æ–¥–∏—Ç –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã"""
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ –±–ª–æ–∫–∞–º (30-60 —Å–µ–∫—É–Ω–¥)
        text_blocks = self.group_transcript_blocks(transcript_segments, block_size=45)
        
        all_moments = []
        
        for block in text_blocks:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –±–ª–æ–∫ —Å –ø–æ–º–æ—â—å—é AI
            moments = self.analyze_text_block(block)
            all_moments.extend(moments)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–∫–∂–µ —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–º–µ–Ω—Ç—ã
            heuristic_moments = self.find_heuristic_moments(block)
            all_moments.extend(heuristic_moments)
        
        return all_moments
    
    def group_transcript_blocks(self, transcript_segments: List[Dict], 
                               block_size: float = 45) -> List[Dict]:
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –±–ª–æ–∫–∞–º"""
        
        blocks = []
        current_block = {
            'start_time': 0,
            'end_time': 0,
            'text': '',
            'segments': []
        }
        
        for segment in transcript_segments:
            segment_start = segment['start']
            
            # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –±–ª–æ–∫ –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –±–æ–ª—å—à–µ block_size —Å–µ–∫—É–Ω–¥
            if segment_start > current_block['start_time'] + block_size:
                if current_block['text']:
                    blocks.append(current_block)
                
                current_block = {
                    'start_time': segment_start,
                    'end_time': segment_start + segment['duration'],
                    'text': segment['text'],
                    'segments': [segment]
                }
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–º—É –±–ª–æ–∫—É
                current_block['end_time'] = segment_start + segment['duration']
                current_block['text'] += ' ' + segment['text']
                current_block['segments'].append(segment)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫
        if current_block['text']:
            blocks.append(current_block)
        
        return blocks
    
    def analyze_text_block(self, block: Dict) -> List[TranscriptMoment]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ —Å –ø–æ–º–æ—â—å—é AI"""
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –≤—Å—Ç—Ä–µ—á–∏ –∏ –Ω–∞–π–¥–∏ –º–æ–º–µ–Ω—Ç—ã, –≥–¥–µ –≤–µ—Ä–æ—è—Ç–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è —á—Ç–æ-—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ.

–í—Ä–µ–º–µ–Ω–Ω–æ–π –æ—Ç—Ä–µ–∑–æ–∫: {block['start_time']:.1f}—Å - {block['end_time']:.1f}—Å

–¢–µ–∫—Å—Ç:
{block['text']}

–ù–∞–π–¥–∏ –º–æ–º–µ–Ω—Ç—ã –≥–¥–µ:
1. –£—á–∞—Å—Ç–Ω–∏–∫ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —ç–∫—Ä–∞–Ω, –∫–æ–¥, –¥–æ–∫—É–º–µ–Ω—Ç, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é
2. –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç—Å—è —Ä–∞–±–æ—Ç–∞ –ø—Ä–æ–≥—Ä–∞–º–º—ã, –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
3. –û–±—ä—è—Å–Ω—è–µ—Ç—Å—è –¥–∏–∞–≥—Ä–∞–º–º–∞, —Å—Ö–µ–º–∞, —á–µ—Ä—Ç–µ–∂
4. –ü—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–µ—Ä–µ—Ö–æ–¥ –∫ –Ω–æ–≤–æ–π —Ç–µ–º–µ/—Å–ª–∞–π–¥—É
5. –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä, —Ä–µ–∑—É–ª—å—Ç–∞—Ç

–î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª–∏:
- timestamp: –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø—Ä–∏–º–µ—Ä–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –æ—Ç—Ä–µ–∑–∫–∞)
- reason: –∫—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ (1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
- importance: –≤–∞–∂–Ω–æ—Å—Ç—å 0.0-1.0
- keywords: –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ —Ä–µ—á–∏
- screenshot_type: —Ç–∏–ø (demo/code/presentation/diagram/ui/document)

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "moments": [
    {{
      "timestamp": 123.5,
      "reason": "–æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–º–µ–Ω—Ç–∞",
      "importance": 0.8,
      "keywords": ["—Å–ª–æ–≤–æ1", "—Å–ª–æ–≤–æ2"],
      "screenshot_type": "code"
    }}
  ]
}}

–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –º–æ–º–µ–Ω—Ç—ã - —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —á–µ—Ç–∫–∏–µ —É–∫–∞–∑–∞–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç–µ."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            moments = []
            
            for moment_data in result.get('moments', []):
                moment = TranscriptMoment(
                    timestamp=moment_data['timestamp'],
                    reason=moment_data['reason'],
                    importance=moment_data['importance'],
                    keywords=moment_data['keywords'],
                    context=block['text'][:200],
                    screenshot_type=moment_data['screenshot_type']
                )
                moments.append(moment)
                
            return moments
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –±–ª–æ–∫–∞: {e}")
            return []
    
    def find_heuristic_moments(self, block: Dict) -> List[TranscriptMoment]:
        """–ù–∞—Ö–æ–¥–∏—Ç –º–æ–º–µ–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª"""
        
        text = block['text'].lower()
        moments = []
        
        # –ò—â–µ–º —Ç—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã
        for pattern in self.trigger_phrases:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                # –ü—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º—è
                char_position = match.start()
                time_ratio = char_position / len(text)
                timestamp = block['start_time'] + (block['end_time'] - block['start_time']) * time_ratio
                
                moment = TranscriptMoment(
                    timestamp=timestamp,
                    reason=f"–¢—Ä–∏–≥–≥–µ—Ä–Ω–∞—è —Ñ—Ä–∞–∑–∞: '{match.group()}'",
                    importance=0.7,
                    keywords=[match.group()],
                    context=text[max(0, char_position-50):char_position+50],
                    screenshot_type="demo"
                )
                moments.append(moment)
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for category, keywords in self.demo_keywords.items():
            if category == "discussion":  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ã—á–Ω—ã–µ –æ–±—Å—É–∂–¥–µ–Ω–∏—è
                continue
                
            for keyword in keywords:
                if keyword in text:
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
                    keyword_pos = text.find(keyword)
                    time_ratio = keyword_pos / len(text)
                    timestamp = block['start_time'] + (block['end_time'] - block['start_time']) * time_ratio
                    
                    moment = TranscriptMoment(
                        timestamp=timestamp,
                        reason=f"–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ '{keyword}' —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ {category}",
                        importance=0.6,
                        keywords=[keyword],
                        context=text[max(0, keyword_pos-30):keyword_pos+30],
                        screenshot_type=category
                    )
                    moments.append(moment)
                    break  # –û–¥–∏–Ω –º–æ–º–µ–Ω—Ç –Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ –±–ª–æ–∫–µ
        
        return moments
    
    def optimize_moments(self, moments: List[TranscriptMoment]) -> List[TranscriptMoment]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ –º–æ–º–µ–Ω—Ç–æ–≤ - —É–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –±–ª–∏–∑–∫–∏–µ"""
        
        if not moments:
            return []
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        moments.sort(key=lambda m: m.timestamp)
        
        optimized = []
        current_group = [moments[0]]
        
        for i in range(1, len(moments)):
            current_moment = moments[i]
            
            # –ï—Å–ª–∏ –º–æ–º–µ–Ω—Ç –±–ª–∏–∑–∫–æ –∫ –ø—Ä–µ–¥—ã–¥—É—â–∏–º (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 10 —Å–µ–∫—É–Ω–¥)
            if current_moment.timestamp - current_group[-1].timestamp < 10:
                current_group.append(current_moment)
            else:
                # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É –∏ –±–µ—Ä–µ–º –ª—É—á—à–∏–π –º–æ–º–µ–Ω—Ç
                best_moment = max(current_group, key=lambda m: m.importance)
                optimized.append(best_moment)
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é –≥—Ä—É–ø–ø—É
                current_group = [current_moment]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
        if current_group:
            best_moment = max(current_group, key=lambda m: m.importance)
            optimized.append(best_moment)
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã)
        high_importance = [m for m in optimized if m.importance >= 0.7]
        
        # –ï—Å–ª–∏ –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤ –º–∞–ª–æ, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ
        if len(high_importance) < 3:
            medium_importance = [m for m in optimized if 0.5 <= m.importance < 0.7]
            high_importance.extend(medium_importance[:5])  # –ú–∞–∫—Å–∏–º—É–º 5 —Å—Ä–µ–¥–Ω–∏—Ö
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        final_moments = sorted(high_importance, key=lambda m: m.importance, reverse=True)[:15]
        final_moments.sort(key=lambda m: m.timestamp)  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        
        return final_moments
    
    def extract_targeted_screenshots(self, video_path: str, output_dir: str,
                                   moments: List[TranscriptMoment],
                                   transcript_segments: List[Dict]) -> List[Tuple]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã"""
        
        cap = cv2.VideoCapture(video_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        screenshots = []
        
        for i, moment in enumerate(moments):
            logger.info(f"üì∏ {i+1}/{len(moments)}: {moment.timestamp:.1f}—Å - {moment.reason}")
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é –≤–∏–¥–µ–æ
            frame_number = int(moment.timestamp * fps)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)
            
            ret, frame = cap.read()
            if not ret:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä –≤ {moment.timestamp:.1f}—Å")
                continue
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –∫–∞–¥—Ä –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ (¬±2 —Å–µ–∫—É–Ω–¥—ã)
            best_frame, best_timestamp = self.find_best_frame_nearby(
                cap, moment.timestamp, fps, window_seconds=2
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç
            filename = f"screenshot_{i+1:03d}_{best_timestamp:.1f}s.png"
            screenshot_path = os.path.join(output_dir, filename)
            
            cv2.imwrite(screenshot_path, best_frame)
            
            # –°–æ–∑–¥–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            description = self.create_screenshot_description(
                moment, best_timestamp, transcript_segments
            )
            
            screenshot_info = {
                'path': screenshot_path,
                'timestamp': best_timestamp,
                'description': description,
                'moment': moment,
                'type': moment.screenshot_type
            }
            
            screenshots.append((screenshot_path, best_timestamp, description, moment.reason))
        
        cap.release()
        return screenshots
    
    def find_best_frame_nearby(self, cap: cv2.VideoCapture, target_time: float,
                              fps: float, window_seconds: float = 2) -> Tuple[np.ndarray, float]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ª—É—á—à–∏–π –∫–∞–¥—Ä –≤ –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç–∏ —Ü–µ–ª–µ–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–∞–¥—Ä—ã –≤ –æ–∫–Ω–µ
        start_time = max(0, target_time - window_seconds)
        end_time = target_time + window_seconds
        
        start_frame = int(start_time * fps)
        end_frame = int(end_time * fps)
        
        best_frame = None
        best_time = target_time
        best_score = -1
        
        for frame_num in range(start_frame, end_frame + 1, int(fps * 0.5)):  # –ö–∞–∂–¥—ã–µ 0.5 —Å–µ–∫
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)
            ret, frame = cap.read()
            
            if not ret:
                continue
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–∞
            score = self.evaluate_frame_quality(frame)
            
            if score > best_score:
                best_score = score
                best_frame = frame.copy()
                best_time = frame_num / fps
        
        return best_frame if best_frame is not None else frame, best_time
    
    def evaluate_frame_quality(self, frame: np.ndarray) -> float:
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–∞"""
        
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑–∫–æ—Å—Ç–∏ (–≤–∞—Ä–∏–∞—Ü–∏—è –õ–∞–ø–ª–∞—Å–∏–∞–Ω–∞)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # –û—Ü–µ–Ω–∫–∞ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        contrast = gray.std()
        
        # –û—Ü–µ–Ω–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–∞–µ–≤)
        edges = cv2.Canny(gray, 50, 150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        quality_score = (
            laplacian_var * 0.4 +
            contrast * 0.3 +
            edge_density * 100 * 0.3
        )
        
        return quality_score
    
    def create_screenshot_description(self, moment: TranscriptMoment,
                                    timestamp: float,
                                    transcript_segments: List[Dict]) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞"""
        
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        context_text = self.get_transcript_context(transcript_segments, timestamp, window=15)
        
        return f"""
**–í—Ä–µ–º—è:** {timestamp:.1f}—Å  
**–ü—Ä–∏—á–∏–Ω–∞:** {moment.reason}  
**–¢–∏–ø:** {moment.screenshot_type}  
**–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞:** {', '.join(moment.keywords)}  
**–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {context_text}
        """.strip()
    
    def get_transcript_context(self, transcript_segments: List[Dict],
                             timestamp: float, window: float = 15) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –≤–æ–∫—Ä—É–≥ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
        
        context_segments = []
        
        for segment in transcript_segments:
            segment_start = segment['start']
            segment_end = segment_start + segment['duration']
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ —Å –æ–∫–Ω–æ–º
            if (segment_start <= timestamp + window and 
                segment_end >= timestamp - window):
                context_segments.append(segment['text'])
        
        return ' '.join(context_segments)


def create_smart_transcript_extractor(video_path: str, output_dir: str,
                                    transcript_segments: List[Dict],
                                    api_key: str) -> List[Tuple]:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–º–Ω–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞"""
    
    extractor = SmartTranscriptExtractor(api_key)
    return extractor.extract_screenshots(video_path, output_dir, transcript_segments) 