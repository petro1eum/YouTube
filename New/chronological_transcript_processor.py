#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
—Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π —Ç–µ–∫—Å—Ç–∞
"""

import os
import json
import re
import base64
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass
from collections import defaultdict
import numpy as np
from openai import OpenAI
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class Speaker:
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—á–∞—Å—Ç–Ω–∏–∫–µ"""
    id: str
    name: Optional[str] = None
    role: Optional[str] = None
    characteristics: List[str] = None
    voice_segments: List[Tuple[float, float]] = None

@dataclass
class TranscriptSegment:
    """–°–µ–≥–º–µ–Ω—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π"""
    start: float
    end: float
    text: str
    speaker_id: Optional[str] = None
    corrected_text: Optional[str] = None
    context_notes: Optional[str] = None
    related_screenshot: Optional[str] = None
    confidence: float = 1.0

@dataclass
class TimelineEvent:
    """–°–æ–±—ã—Ç–∏–µ –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ª–∏–Ω–∏–∏"""
    timestamp: float
    type: str  # 'transcript', 'screenshot', 'topic_change', 'speaker_change'
    content: Dict
    importance: float = 0.5

class ChronologicalTranscriptProcessor:
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.client = OpenAI(api_key=api_key)
        self.speakers = {}
        self.timeline_events = []
        self.topics = []
        self.context_buffer = []
        
    def process_video_meeting(self, transcript_segments: List[Dict], 
                            screenshots: List[Tuple],
                            video_context: Dict) -> Dict:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ –≤—Å—Ç—Ä–µ—á–∏"""
        
        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞...")
        
        # 1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
        speakers = self.identify_speakers(transcript_segments)
        logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {len(speakers)}")
        
        # 2. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é —Å–æ–±—ã—Ç–∏–π
        timeline = self.create_timeline(transcript_segments, screenshots)
        
        # 3. –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        corrected_timeline = self.correct_transcript_with_context(
            timeline, speakers, video_context
        )
        
        # 4. –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–µ–º–∞–º –∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
        structured_content = self.structure_content(corrected_timeline, speakers)
        
        # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report = self.generate_chronological_report(structured_content, speakers)
        
        return {
            'speakers': speakers,
            'timeline': corrected_timeline,
            'structured_content': structured_content,
            'report': report
        }
    
    def identify_speakers(self, transcript_segments: List[Dict]) -> Dict[str, Speaker]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞"""
        
        # –°–æ–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–µ 10 –º–∏–Ω—É—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        early_segments = []
        for segment in transcript_segments:
            if segment['start'] < 600:  # 10 –º–∏–Ω—É—Ç
                early_segments.append(segment)
        
        early_text = '\n'.join([s['text'] for s in early_segments])
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤—Å—Ç—Ä–µ—á–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤.

–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–µ—Ä–≤—ã—Ö –º–∏–Ω—É—Ç:
{early_text[:3000]}

–û–ø—Ä–µ–¥–µ–ª–∏:
1. –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (speakers)
2. –ò—Ö –≤–µ—Ä–æ—è—Ç–Ω—ã–µ –∏–º–µ–Ω–∞ (–µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è)
3. –ò—Ö —Ä–æ–ª–∏ (–≤–µ–¥—É—â–∏–π, –¥–æ–∫–ª–∞–¥—á–∏–∫, —É—á–∞—Å—Ç–Ω–∏–∫ –∏ —Ç.–¥.)
4. –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∏–ª–∏ —Å—Ç–∏–ª—å —Ä–µ—á–∏ –∫–∞–∂–¥–æ–≥–æ
5. –ü–∞—Ç—Ç–µ—Ä–Ω—ã —Å–º–µ–Ω—ã –≥–æ–≤–æ—Ä—è—â–∏—Ö

–û—Ç–≤–µ—Ç—å –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{{
    "speakers": [
        {{
            "id": "speaker1",
            "probable_name": "–∏–º—è –µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ –∏–ª–∏ null",
            "role": "—Ä–æ–ª—å",
            "characteristics": ["—Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ—á–∏"],
            "speech_patterns": ["–ø—Ä–∏–º–µ—Ä—ã —Ñ—Ä–∞–∑"]
        }}
    ],
    "speaker_change_indicators": ["–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–º–µ–Ω—ã –≥–æ–≤–æ—Ä—è—â–µ–≥–æ"],
    "meeting_format": "—Ñ–æ—Ä–º–∞—Ç –≤—Å—Ç—Ä–µ—á–∏ (–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è/–¥–∏—Å–∫—É—Å—Å–∏—è/–∏–Ω—Ç–µ—Ä–≤—å—é)"
}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã Speaker
            speakers = {}
            for speaker_data in result.get('speakers', []):
                speaker = Speaker(
                    id=speaker_data['id'],
                    name=speaker_data.get('probable_name'),
                    role=speaker_data.get('role', '—É—á–∞—Å—Ç–Ω–∏–∫'),
                    characteristics=speaker_data.get('characteristics', []),
                    voice_segments=[]
                )
                speakers[speaker.id] = speaker
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–º–µ–Ω—ã –≥–æ–≤–æ—Ä—è—â–∏—Ö
            self.speaker_change_indicators = result.get('speaker_change_indicators', [])
            self.meeting_format = result.get('meeting_format', 'discussion')
            
            # –¢–µ–ø–µ—Ä—å –ø—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—É –∏ –Ω–∞–∑–Ω–∞—á–∞–µ–º –≥–æ–≤–æ—Ä—è—â–∏—Ö
            self.assign_speakers_to_segments(transcript_segments, speakers)
            
            return speakers
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–¥–Ω–æ–≥–æ –¥–µ—Ñ–æ–ª—Ç–Ω–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞
            default_speaker = Speaker(id="speaker1", name="–£—á–∞—Å—Ç–Ω–∏–∫", role="speaker")
            return {"speaker1": default_speaker}
    
    def assign_speakers_to_segments(self, transcript_segments: List[Dict], 
                                  speakers: Dict[str, Speaker]):
        """–ù–∞–∑–Ω–∞—á–∞–µ—Ç –≥–æ–≤–æ—Ä—è—â–∏—Ö –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞"""
        
        current_speaker = "speaker1"
        context_window = []
        
        for i, segment in enumerate(transcript_segments):
            # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            context = self.get_segment_context(transcript_segments, i, window_size=5)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –¥–ª—è —Å–µ–≥–º–µ–Ω—Ç–∞
            speaker_id = self.detect_speaker_for_segment(
                segment, context, speakers, current_speaker
            )
            
            segment['speaker_id'] = speaker_id
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–µ–≥–º–µ–Ω—Ç–∞—Ö –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
            if speaker_id in speakers:
                speakers[speaker_id].voice_segments.append(
                    (segment['start'], segment.get('end', segment['start'] + segment['duration']))
                )
            
            current_speaker = speaker_id
    
    def detect_speaker_for_segment(self, segment: Dict, context: List[Dict],
                                 speakers: Dict[str, Speaker], 
                                 current_speaker: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞"""
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –Ω–∞—á–∞–ª–∞
        text_lower = segment['text'].lower()
        
        # –ò—â–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–º–µ–Ω—ã –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
        for indicator in self.speaker_change_indicators:
            if indicator.lower() in text_lower:
                # –í–µ—Ä–æ—è—Ç–Ω–æ —Å–º–µ–Ω–∞ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
                # –í—ã–±–∏—Ä–∞–µ–º —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ —Ü–∏–∫–ª—É
                speaker_ids = list(speakers.keys())
                current_idx = speaker_ids.index(current_speaker)
                next_idx = (current_idx + 1) % len(speaker_ids)
                return speaker_ids[next_idx]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ —Ñ—Ä–∞–∑—ã –∫–∞–∂–¥–æ–≥–æ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
        best_match = current_speaker
        best_score = 0
        
        for speaker_id, speaker in speakers.items():
            score = 0
            for characteristic in speaker.characteristics:
                if characteristic.lower() in text_lower:
                    score += 1
            
            if score > best_score:
                best_score = score
                best_match = speaker_id
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª–∏–Ω—É –ø–∞—É–∑
        if len(context) > 0:
            prev_segment = context[-1]
            pause = segment['start'] - (prev_segment['start'] + prev_segment.get('duration', 0))
            if pause > 2.0:  # –ü–∞—É–∑–∞ –±–æ–ª—å—à–µ 2 —Å–µ–∫—É–Ω–¥ - –≤–æ–∑–º–æ–∂–Ω–æ —Å–º–µ–Ω–∞ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
                # –í–µ—Ä–æ—è—Ç–Ω–æ —Å–º–µ–Ω–∞
                speaker_ids = list(speakers.keys())
                if len(speaker_ids) > 1 and best_score == 0:
                    current_idx = speaker_ids.index(current_speaker)
                    next_idx = (current_idx + 1) % len(speaker_ids)
                    return speaker_ids[next_idx]
        
        return best_match if best_score > 0 else current_speaker
    
    def get_segment_context(self, segments: List[Dict], current_idx: int, 
                          window_size: int = 5) -> List[Dict]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–æ–∫—Ä—É–≥ —Å–µ–≥–º–µ–Ω—Ç–∞"""
        start_idx = max(0, current_idx - window_size)
        end_idx = min(len(segments), current_idx + window_size + 1)
        return segments[start_idx:end_idx]
    
    def create_timeline(self, transcript_segments: List[Dict], 
                       screenshots: List[Tuple]) -> List[TimelineEvent]:
        """–°–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"""
        
        timeline = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
        for segment in transcript_segments:
            event = TimelineEvent(
                timestamp=segment['start'],
                type='transcript',
                content={
                    'text': segment['text'],
                    'duration': segment.get('duration', 0),
                    'speaker_id': segment.get('speaker_id', 'unknown'),
                    'original_segment': segment
                }
            )
            timeline.append(event)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã
        for screenshot_path, timestamp, description, reason in screenshots:
            event = TimelineEvent(
                timestamp=float(timestamp),
                type='screenshot',
                content={
                    'path': screenshot_path,
                    'description': description,
                    'reason': reason
                },
                importance=0.8  # –°–∫—Ä–∏–Ω—à–æ—Ç—ã –æ–±—ã—á–Ω–æ –≤–∞–∂–Ω—ã
            )
            timeline.append(event)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        timeline.sort(key=lambda x: x.timestamp)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–µ–º
        self.detect_topic_changes(timeline)
        
        return timeline
    
    def detect_topic_changes(self, timeline: List[TimelineEvent]):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–æ–º–µ–Ω—Ç—ã —Å–º–µ–Ω—ã —Ç–µ–º—ã –æ–±—Å—É–∂–¥–µ–Ω–∏—è"""
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–±—ã—Ç–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        text_groups = []
        current_group = []
        
        for event in timeline:
            if event.type == 'transcript':
                current_group.append(event)
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–µ 10 —Å–µ–≥–º–µ–Ω—Ç–æ–≤
                if len(current_group) >= 10:
                    self.analyze_topic_group(current_group, timeline)
                    current_group = current_group[-5:]  # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
        if current_group:
            self.analyze_topic_group(current_group, timeline)
    
    def analyze_topic_group(self, text_events: List[TimelineEvent], 
                          timeline: List[TimelineEvent]):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–±—ã—Ç–∏–π –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ç–µ–º—ã"""
        
        texts = [e.content['text'] for e in text_events]
        combined_text = ' '.join(texts)
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º—ã
        # –í —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –∑–¥–µ—Å—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        topic_keywords = {
            '–≤–≤–µ–¥–µ–Ω–∏–µ': ['–ø—Ä–∏–≤–µ—Ç', '–¥–æ–±—Ä—ã–π –¥–µ–Ω—å', '–Ω–∞—á–Ω–µ–º', '–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—é—Å—å'],
            '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è': ['—Å–ª–∞–π–¥', '–ø–æ–∫–∞–∂—É', '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è', '–ø—Ä–∏–º–µ—Ä'],
            '–∫–æ–¥': ['–∫–æ–¥', '—Ñ—É–Ω–∫—Ü–∏—è', '–º–µ—Ç–æ–¥', '–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è', '–∫–ª–∞—Å—Å'],
            '–æ–±—Å—É–∂–¥–µ–Ω–∏–µ': ['–≤–æ–ø—Ä–æ—Å', '—á—Ç–æ –¥—É–º–∞–µ—Ç–µ', '–º–Ω–µ–Ω–∏–µ', '–æ–±—Å—É–¥–∏–º'],
            '–∑–∞–∫–ª—é—á–µ–Ω–∏–µ': ['–∏—Ç–æ–≥', '–≤—ã–≤–æ–¥', '—Ä–µ–∑—é–º–µ', '—Å–ø–∞—Å–∏–±–æ', '–≤–æ–ø—Ä–æ—Å—ã']
        }
        
        detected_topic = None
        max_score = 0
        
        for topic, keywords in topic_keywords.items():
            score = sum(1 for kw in keywords if kw in combined_text.lower())
            if score > max_score:
                max_score = score
                detected_topic = topic
        
        if detected_topic and max_score > 2:
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ —Å–º–µ–Ω—ã —Ç–µ–º—ã
            topic_event = TimelineEvent(
                timestamp=text_events[0].timestamp,
                type='topic_change',
                content={'topic': detected_topic},
                importance=0.6
            )
            timeline.append(topic_event)
    
    def extract_terminology_from_screenshots(self, screenshot_events: List[TimelineEvent]) -> Dict:
        """–ê–ì–ï–ù–¢ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ Whisper"""
        
        logger.info("ü§ñ –ê–ì–ï–ù–¢ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏...")
        
        terminology_dict = {'by_timestamp': {}, 'all_terms': set()}
        
        for event in screenshot_events:
            detailed_content = event.content.get('detailed_content', {})
            if not detailed_content:
                continue
            
            timestamp = event.timestamp
            
            # –ê–ì–ï–ù–¢ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–∞–∂–¥–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
            prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ –∏–∑ –¥–µ–ª–æ–≤—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏ –í–°–Æ —Ç–æ—á–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.

–°–û–î–ï–†–ñ–ò–ú–û–ï –°–ö–†–ò–ù–®–û–¢–ê:
–¢–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞: {detailed_content.get('main_content_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}
–í–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç: {detailed_content.get('visible_text', '')}
–ö–æ–¥/–∫–æ–º–∞–Ω–¥—ã: {detailed_content.get('code_snippets', [])}
–î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü: {detailed_content.get('table_data', [])}
UI —ç–ª–µ–º–µ–Ω—Ç—ã: {detailed_content.get('ui_elements', [])}
–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏: {detailed_content.get('technical_details', [])}

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ç–µ—Ä–º–∏–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã Whisper:
- –ù–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π, —Ç–∞–±–ª–∏—Ü, –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
- –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤, —Ñ—É–Ω–∫—Ü–∏–π, –º–µ—Ç–æ–¥–æ–≤
- –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
- –¢–æ—á–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –¥–∞—Ç—ã
- UI —ç–ª–µ–º–µ–Ω—Ç—ã (–∫–Ω–æ–ø–∫–∏, –ø–æ–ª—è)
- –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–æ–≤/—Å–∏—Å—Ç–µ–º

–í–ê–ñ–ù–û: –£—á–∏—Ç—ã–≤–∞–π, —á—Ç–æ Whisper —á–∞—Å—Ç–æ:
- –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π
- –ò—Å–∫–∞–∂–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —á–∏—Å–ª–∞ –∏ –¥–∞—Ç—ã
- –ü—É—Ç–∞–µ—Ç –ø–æ—Ö–æ–∂–∏–µ –ø–æ –∑–≤—É—á–∞–Ω–∏—é —Å–ª–æ–≤–∞

–í–µ—Ä–Ω–∏ JSON —Å —Ç–µ—Ä–º–∏–Ω–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤–∞–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –≤ —Ä–µ—á–∏:
{{
    "critical_terms": ["—Å–ø–∏—Å–æ–∫ —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"],
    "field_names": ["–Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π/–ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"],
    "exact_values": ["—Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —á–∏—Å–ª–∞, –¥–∞—Ç—ã"],
    "file_names": ["–∏–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤"],
    "ui_elements": ["—ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"],
    "whisper_errors": [
        {{
            "correct": "–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ—Ä–º–∏–Ω",
            "likely_errors": ["–≤–æ–∑–º–æ–∂–Ω—ã–µ –æ—à–∏–±–∫–∏ Whisper"]
        }}
    ]
}}"""

            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o",
                    messages=[{"role": "user", "content": prompt}],
                    response_format={"type": "json_object"},
                    temperature=0.1
                )
                
                result = json.loads(response.choices[0].message.content)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                terminology_dict['by_timestamp'][timestamp] = result
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π —Å–ª–æ–≤–∞—Ä—å
                for category, terms in result.items():
                    if category != 'whisper_errors' and isinstance(terms, list):
                        terminology_dict['all_terms'].update(terms)
                
                logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(result.get('critical_terms', []))} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ {timestamp:.1f}—Å")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏: {e}")
        
        total_terms = len(terminology_dict['all_terms'])
        logger.info(f"üéØ –ê–ì–ï–ù–¢ –∏–∑–≤–ª–µ–∫ {total_terms} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–∑ {len(screenshot_events)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
        
        return terminology_dict
    

    
    def correct_whisper_with_terminology(self, text: str, terminology_dict: Dict, 
                                       timestamp: float) -> str:
        """–ê–ì–ï–ù–¢ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –æ—à–∏–±–∫–∏ Whisper –∏—Å–ø–æ–ª—å–∑—É—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"""
        
        if not text or not terminology_dict:
            return text
            
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (¬±30 —Å–µ–∫—É–Ω–¥)
        relevant_terminology = []
        for ts, terms_data in terminology_dict.get('by_timestamp', {}).items():
            if abs(ts - timestamp) <= 30:  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 30 —Å–µ–∫—É–Ω–¥
                relevant_terminology.append({
                    'timestamp': ts,
                    'terms': terms_data
                })
        
        if not relevant_terminology:
            return text
        
        # –ê–ì–ï–ù–¢ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—é –æ—à–∏–±–æ–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ Whisper. –£ —Ç–µ–±—è –µ—Å—Ç—å –¢–û–ß–ù–ê–Ø —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤.

–ò–°–•–û–î–ù–´–ô –¢–ï–ö–°–¢ (—Å –æ—à–∏–±–∫–∞–º–∏ Whisper):
"{text}"

–¢–û–ß–ù–ê–Ø –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Ø –ò–ó –°–ö–†–ò–ù–®–û–¢–û–í:
{json.dumps(relevant_terminology, ensure_ascii=False, indent=2)}

–¢–í–û–Ø –ó–ê–î–ê–ß–ê:
–ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ Whisper, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–ß–ù–£–Æ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é —Å–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤:

1. üîç –ù–∞–π–¥–∏ –∏—Å–∫–∞–∂–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –≤ —Ç–µ–∫—Å—Ç–µ
2. ‚úèÔ∏è  –ó–∞–º–µ–Ω–∏ –∏—Ö –Ω–∞ –¢–û–ß–ù–´–ï –≤–µ—Ä—Å–∏–∏ –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤  
3. üìù –ò—Å–ø—Ä–∞–≤—å —Ç–æ–ª—å–∫–æ —è–≤–Ω—ã–µ –æ—à–∏–±–∫–∏, –Ω–µ –º–µ–Ω—è–π —Å–º—ã—Å–ª
4. üéØ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π, —Ñ–∞–π–ª–æ–≤, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ç–µ—Ä–º–∏–Ω–∞–º

–¢–ò–ü–ò–ß–ù–´–ï –û–®–ò–ë–ö–ò WHISPER:
- "–¥–∞—Ç–∞ –±–∞—Å–µ" ‚Üí "database"  
- "—Ñ–∞–π–ª —Ç–∞–±–ª–∏—Ü—ã" ‚Üí –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Ç–∞–±–ª–∏—Ü—ã
- "–∫–Ω–æ–ø–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å" ‚Üí —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–æ–ø–∫–∏
- —á–∏—Å–ª–∞ —Å–ª–æ–≤–∞–º–∏ ‚Üí —Ü–∏—Ñ—Ä—ã

–í–µ—Ä–Ω–∏ JSON:
{{
    "corrected_text": "–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
    "corrections": [
        {{
            "original": "–æ—à–∏–±–æ—á–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç",
            "corrected": "–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ—Ä–º–∏–Ω",
            "source": "–æ—Ç–∫—É–¥–∞ –≤–∑—è—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–µ—Ä–º–∏–Ω"
        }}
    ]
}}

–í–ê–ñ–ù–û: –ò—Å–ø—Ä–∞–≤–ª—è–π —Ç–æ–ª—å–∫–æ —Ç–æ, —á—Ç–æ –µ—Å—Ç—å –≤ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏!"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.1
            )
            
            result = json.loads(response.choices[0].message.content)
            corrected_text = result.get('corrected_text', text)
            corrections = result.get('corrections', [])
            
            if corrections:
                logger.info(f"ü§ñ –ê–ì–ï–ù–¢ –∏—Å–ø—Ä–∞–≤–∏–ª {len(corrections)} –æ—à–∏–±–æ–∫ Whisper –≤ {timestamp:.1f}—Å")
                for correction in corrections[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                    logger.info(f"   ‚úèÔ∏è  '{correction['original']}' ‚Üí '{correction['corrected']}'")
            
            return corrected_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –ê–ì–ï–ù–¢–û–ú: {e}")
            return text
    

    
    def correct_transcript_with_context(self, timeline: List[TimelineEvent],
                                      speakers: Dict[str, Speaker],
                                      video_context: Dict) -> List[TimelineEvent]:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å —É—á–µ—Ç–æ–º –ü–û–õ–ù–û–ì–û –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"""
        
        logger.info("üîß –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Å —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–µ–π –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å–æ–±—ã—Ç–∏—è –ø–æ —Ç–∏–ø–∞–º
        transcript_events = [e for e in timeline if e.type == 'transcript']
        screenshot_events = [e for e in timeline if e.type == 'screenshot']
        
        if not transcript_events:
            return timeline
        
        # 1. –ù–û–í–û–ï: –î–æ–ø–æ–ª–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        enhanced_screenshots = self.enhance_screenshots_with_content(screenshot_events)
        
        # 2. –ù–û–í–û–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        terminology_dict = self.extract_terminology_from_screenshots(enhanced_screenshots)
        
        # 3. –ù–û–í–û–ï: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º Whisper –æ—à–∏–±–∫–∏ —Å –ø–æ–º–æ—â—å—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏
        for event in transcript_events:
            original_text = event.content['text']
            corrected_text = self.correct_whisper_with_terminology(
                original_text, terminology_dict, event.timestamp
            )
            event.content['text'] = corrected_text
            event.content['whisper_corrections'] = corrected_text != original_text
        
        # 4. –û—Å–Ω–æ–≤–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏
        corrected_events = self.correct_with_context_blocks(
            transcript_events, enhanced_screenshots, speakers, video_context, terminology_dict
        )
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π timeline —Å –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
        corrected_timeline = []
        transcript_map = {e.timestamp: e for e in corrected_events}
        
        for event in timeline:
            if event.type == 'transcript' and event.timestamp in transcript_map:
                corrected_timeline.append(transcript_map[event.timestamp])
            elif event.type == 'screenshot':
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã
                enhanced_event = next((e for e in enhanced_screenshots if e.timestamp == event.timestamp), event)
                corrected_timeline.append(enhanced_event)
            else:
                corrected_timeline.append(event)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        corrected_timeline.sort(key=lambda x: x.timestamp)
        
        return corrected_timeline
    
    def create_processing_groups(self, timeline: List[TimelineEvent], 
                               group_duration: float = 30.0) -> List[List[TimelineEvent]]:
        """–°–æ–∑–¥–∞–µ—Ç –≥—Ä—É–ø–ø—ã —Å–æ–±—ã—Ç–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        groups = []
        current_group = []
        group_start = 0
        
        for event in timeline:
            if not current_group:
                group_start = event.timestamp
                current_group.append(event)
            elif event.timestamp - group_start <= group_duration:
                current_group.append(event)
            else:
                groups.append(current_group)
                current_group = [event]
                group_start = event.timestamp
        
        if current_group:
            groups.append(current_group)
        
        return groups
    
    def correct_whole_transcript(self, transcript_events: List[TimelineEvent],
                               screenshot_events: List[TimelineEvent],
                               speakers: Dict[str, Speaker],
                               video_context: Dict) -> List[TimelineEvent]:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –í–ï–°–¨ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Ü–µ–ª–∏–∫–æ–º —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        logger.info("üîß –£–ª—É—á—à–µ–Ω–Ω–∞—è –∫–æ—Ä—Ä–µ–∫—Ü–∏—è —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª–µ–π...")
        
        # –°–æ–±–∏—Ä–∞–µ–º –ü–û–õ–ù–´–ô –¥–∏–∞–ª–æ–≥ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        full_dialogue = []
        speaker_profiles = {}
        
        for event in transcript_events:
            speaker_id = event.content.get('speaker_id', 'unknown')
            speaker_name = speakers.get(speaker_id, Speaker(id=speaker_id)).name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1] if speaker_id != 'unknown' else '1'}"
            
            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ—Ñ–∏–ª–∏ —Å–ø–∏–∫–µ—Ä–æ–≤
            if speaker_name not in speaker_profiles:
                speaker_profiles[speaker_name] = {
                    'total_speech': [],
                    'topics': set(),
                    'style': '—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π'
                }
            
            text = event.content['text']
            speaker_profiles[speaker_name]['total_speech'].append(text)
            
            full_dialogue.append({
                'time': event.timestamp,
                'speaker': speaker_name,
                'text': text,
                'original_event': event
            })
        
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞—Ö
        visual_context = ""
        if screenshot_events:
            visual_context = "\n\n–í–∏–∑—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –≤–∏–¥–µ–æ:\n"
            for ss_event in screenshot_events:
                time_str = f"{int(ss_event.timestamp//60)}:{int(ss_event.timestamp%60):02d}"
                desc = ss_event.content.get('description', '')
                reason = ss_event.content.get('reason', '–∏–∑–º–µ–Ω–µ–Ω–∏–µ')
                visual_context += f"[{time_str}] {reason}: {desc}\n"
        
        # üöÄ –ù–û–í–´–ô –ü–û–î–•–û–î: —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è –±–ª–æ–∫–∏
        corrected_events = self.correct_with_context_blocks(
            full_dialogue, speaker_profiles, visual_context, video_context
        )
        
        logger.info(f"‚úÖ –û—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(corrected_events)} —Ä–µ–ø–ª–∏–∫ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–µ—Ç–∞–ª–µ–π")
        return corrected_events
    
    def correct_with_context_blocks(self, transcript_events: List[TimelineEvent], 
                                   enhanced_screenshots: List[TimelineEvent],
                                   speakers: Dict[str, Speaker],
                                   video_context: Dict, terminology_dict: Dict) -> List[TimelineEvent]:
        """–ù–æ–≤—ã–π –º–µ—Ç–æ–¥ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏ + —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤"""
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–æ–±—ã—Ç–∏—è –≤ –¥–∏–∞–ª–æ–≥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        full_dialogue = []
        speaker_profiles = {}
        
        for event in transcript_events:
            speaker_id = event.content.get('speaker_id', 'unknown')
            speaker_name = speakers.get(speaker_id, Speaker(id=speaker_id)).name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1] if speaker_id != 'unknown' else '1'}"
            
            # –°—Ç—Ä–æ–∏–º –ø—Ä–æ—Ñ–∏–ª–∏ —Å–ø–∏–∫–µ—Ä–æ–≤
            if speaker_name not in speaker_profiles:
                speaker_profiles[speaker_name] = {
                    'total_speech': [],
                    'topics': set(),
                    'style': '—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π'
                }
            
            text = event.content['text']
            speaker_profiles[speaker_name]['total_speech'].append(text)
            
            full_dialogue.append({
                'time': event.timestamp,
                'speaker': speaker_name,
                'text': text,
                'original_event': event
            })
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –±–ª–æ–∫–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ 15-20 —Ä–µ–ø–ª–∏–∫)
        block_size = 20
        overlap_size = 5  # –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        corrected_events = []
        
        for block_start in range(0, len(full_dialogue), block_size - overlap_size):
            block_end = min(block_start + block_size, len(full_dialogue))
            
            # –¢–µ–∫—É—â–∏–π –±–ª–æ–∫
            current_block = full_dialogue[block_start:block_end]
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ –±–ª–æ–∫–∞ (–ø—Ä–µ–¥—ã–¥—É—â–∏–µ 3 —Ä–µ–ø–ª–∏–∫–∏)
            context_before = full_dialogue[max(0, block_start-3):block_start]
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –±–ª–æ–∫–∞ (—Å–ª–µ–¥—É—é—â–∏–µ 3 —Ä–µ–ø–ª–∏–∫–∏) 
            context_after = full_dialogue[block_end:min(len(full_dialogue), block_end+3)]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞
            block_theme = self.analyze_block_theme(current_block)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω –±–ª–æ–∫–∞
            block_start_time = current_block[0]['time'] if current_block else 0
            block_end_time = current_block[-1]['time'] if current_block else 0
            
            logger.info(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫ {block_start//block_size + 1}: —Ä–µ–ø–ª–∏–∫–∏ {block_start+1}-{block_end} (—Ç–µ–º–∞: {block_theme})")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞
            visual_context = self.get_screenshot_content_for_time(
                enhanced_screenshots, (block_start_time + block_end_time) / 2, window=60
            )
            
            # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –±–ª–æ–∫ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º + —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è
            corrected_block = self.correct_context_block(
                current_block, context_before, context_after,
                block_theme, speaker_profiles, visual_context, video_context, terminology_dict
            )
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è (–∏–∑–±–µ–≥–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–∏ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–∏)
            start_idx = overlap_size if block_start > 0 else 0
            for i in range(start_idx, len(corrected_block)):
                corrected_events.append(corrected_block[i])
        
        return corrected_events
    
    def analyze_block_theme(self, block: List[Dict]) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–º–∞—Ç–∏–∫—É –±–ª–æ–∫–∞ –¥–∏–∞–ª–æ–≥–∞"""
        
        block_text = ' '.join([item['text'] for item in block]).lower()
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–º—ã
        themes = {
            '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ': ['–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ', '—Å–∏—Å—Ç–µ–º–∞', '–¥–∞–Ω–Ω—ã–µ', '–±–∞–∑–∞', '—Ç–∞–±–ª–∏—Ü–∞', '—Å—Ö–µ–º–∞'],
            '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ': ['–ø–ª–∞–Ω', '–∑–∞–¥–∞—á–∞', '—Å—Ä–æ–∫–∏', '–¥–µ–¥–ª–∞–π–Ω', '–≥—Ä–∞—Ñ–∏–∫'],
            '–∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º': ['–ø—Ä–æ–±–ª–µ–º–∞', '–æ—à–∏–±–∫–∞', '–∏—Å–ø—Ä–∞–≤–∏—Ç—å', '—Ä–µ—à–µ–Ω–∏–µ', '–±–∞–≥'],
            '–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è': ['–ø–æ–∫–∞–∑–∞—Ç—å', '—Å–º–æ—Ç—Ä–µ—Ç—å', '—ç–∫—Ä–∞–Ω', '—Å–ª–∞–π–¥', '–∫–æ–¥'],
            '–æ–±—Å—É–∂–¥–µ–Ω–∏–µ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤': ['–ø—Ä–æ—Ü–µ—Å—Å', '—ç—Ç–∞–ø', '—à–∞–≥', '–ø–æ—Ä—è–¥–æ–∫', '–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å']
        }
        
        best_theme = '–æ–±—â–µ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ'
        max_score = 0
        
        for theme, keywords in themes.items():
            score = sum(1 for keyword in keywords if keyword in block_text)
            if score > max_score:
                max_score = score
                best_theme = theme
        
        return best_theme
    
    def correct_context_block(self, current_block: List[Dict],
                             context_before: List[Dict], context_after: List[Dict],
                             block_theme: str, speaker_profiles: Dict,
                             visual_context: str, video_context: Dict,
                             terminology_dict: Dict) -> List[TimelineEvent]:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –±–ª–æ–∫ —Å —É—á–µ—Ç–æ–º –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        context_info = ""
        if context_before:
            context_info += "–ü–†–ï–î–®–ï–°–¢–í–£–Æ–©–ò–ô –ö–û–ù–¢–ï–ö–°–¢:\n"
            for item in context_before:
                time_str = f"{int(item['time']//60)}:{int(item['time']%60):02d}"
                context_info += f"[{time_str}] {item['speaker']}: {item['text']}\n"
            context_info += "\n"
        
        # –¢–µ–∫—É—â–∏–π –±–ª–æ–∫
        current_text = ""
        for item in current_block:
            time_str = f"{int(item['time']//60)}:{int(item['time']%60):02d}"
            current_text += f"[{time_str}] {item['speaker']}: {item['text']}\n"
        
        # –ü–æ—Å–ª–µ–¥—É—é—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if context_after:
            context_info += "\n–ü–û–°–õ–ï–î–£–Æ–©–ò–ô –ö–û–ù–¢–ï–ö–°–¢:\n"
            for item in context_after:
                time_str = f"{int(item['time']//60)}:{int(item['time']%60):02d}"
                context_info += f"[{time_str}] {item['speaker']}: {item['text']}\n"
        
        # ü§ñ –ê–ì–ï–ù–¢–ù–´–ô –ü–†–û–ú–ü–¢ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏ –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—é —Ç–æ—á–Ω–æ–≥–æ —Å–º—ã—Å–ª–∞ –¥–µ–ª–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á. –£ —Ç–µ–±—è –µ—Å—Ç—å –î–ï–¢–ê–õ–¨–ù–ê–Ø –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —ç–∫—Ä–∞–Ω–∞ + —Ç–æ—á–Ω–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è.

–ö–û–ù–¢–ï–ö–°–¢ –í–°–¢–†–ï–ß–ò:
- –¢–∏–ø: {video_context.get('meeting_type', '–¥–µ–ª–æ–≤–∞—è –≤—Å—Ç—Ä–µ—á–∞')}
- –¢–µ–º–∞—Ç–∏–∫–∞ –±–ª–æ–∫–∞: {block_theme}
- –£—á–∞—Å—Ç–Ω–∏–∫–∏: {', '.join(speaker_profiles.keys())}

{context_info}

–û–°–ù–û–í–ù–û–ô –ë–õ–û–ö –î–õ–Ø –ö–û–†–†–ï–ö–¶–ò–ò:
{current_text}

–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –° –≠–ö–†–ê–ù–ê:
{visual_context}

–ò–ó–í–õ–ï–ß–ï–ù–ù–ê–Ø –¢–ï–†–ú–ò–ù–û–õ–û–ì–ò–Ø –ò–ó –°–ö–†–ò–ù–®–û–¢–û–í:
{json.dumps(terminology_dict, default=lambda x: list(x) if isinstance(x, set) else x, ensure_ascii=False, indent=2)[:2000]}

–¢–í–û–Ø –ì–õ–ê–í–ù–ê–Ø –ó–ê–î–ê–ß–ê:
üéØ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏ –¢–û–ß–ù–´–ô —Å–º—ã—Å–ª –¥–∏–∞–ª–æ–≥–∞, –∏—Å–ø–æ–ª—å–∑—É—è:
1. –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ (—á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –≤–∏–¥–Ω–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ)
2. –¢–æ—á–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π, —Ñ–∞–π–ª–æ–≤, —Å–∏—Å—Ç–µ–º)
3. –¢–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é (–∫–æ–¥—ã, –¥–∞–Ω–Ω—ã–µ, –∫–æ–º–∞–Ω–¥—ã)
4. –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (—á—Ç–æ –±—ã–ª–æ –¥–æ –∏ –ø–æ—Å–ª–µ)

–û–°–û–ë–û–ï –í–ù–ò–ú–ê–ù–ò–ï:
üí° –ï—Å–ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫ –≥–æ–≤–æ—Ä–∏—Ç –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–≤–æ—Ç –∑–¥–µ—Å—å", "—ç—Ç–æ –ø–æ–ª–µ", "—ç—Ç–∞ —Ç–∞–±–ª–∏—Ü–∞" - 
   –∑–∞–º–µ–Ω–∏ –Ω–∞ –ö–û–ù–ö–†–ï–¢–ù–´–ï –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤!

üîç –ï—Å–ª–∏ Whisper –∏—Å–∫–∞–∑–∏–ª —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã - –∏—Å–ø—Ä–∞–≤—å –ø–æ —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏–∏!

üìä –ï—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è –¥–∞–Ω–Ω—ã–µ/—á–∏—Å–ª–∞ - –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å —ç–∫—Ä–∞–Ω–∞!

–ü–†–ò–ú–ï–†–´ –£–õ–£–ß–®–ï–ù–ò–ô:
‚ùå "–¢–∞–º —Ä–∞–∑–æ–±—Ä–∞–ª–∏ —Å–æ–±—Ä–∞–ª–∏ —Å–Ω–æ–≤–∞ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏" 
‚úÖ "–û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ model_X123 —Ä–∞–∑–æ–±—Ä–∞–ª–∏, –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ —Å–∏—Å—Ç–µ–º—É inventory_tracking, –≤—ã—è–≤–∏–ª–∏ –æ—à–∏–±–∫–∏ –≤ –ø–æ–ª–µ date_received, –∑–∞—Ç–µ–º —Å–æ–±—Ä–∞–ª–∏ –∏ –æ—Ç–ø—Ä–∞–≤–∏–ª–∏"

‚ùå "–ó–¥–µ—Å—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ—á–∫–∞ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é"
‚úÖ "–í —Ç–∞–±–ª–∏—Ü–µ equipment_log —Å–ª–µ–¥—É—é—â–∞—è –∑–∞–ø–∏—Å—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å 'completed' –¥–ª—è –µ–¥–∏–Ω–∏—Ü—ã —Å ID 15847"

–í–µ—Ä–Ω–∏ JSON —Å –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –î–ï–¢–ê–õ–¨–ù–´–ú–ò —Ä–µ–ø–ª–∏–∫–∞–º–∏:
{{
    "corrected_dialogue": [
        {{
            "timestamp": –≤—Ä–µ–º–µ–Ω–Ω–∞—è_–º–µ—Ç–∫–∞,
            "speaker": "–∏–º—è_—Å–ø–∏–∫–µ—Ä–∞",
            "corrected_text": "–ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –î–ï–¢–ê–õ–¨–ù–ê–Ø —Ä–µ–ø–ª–∏–∫–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏, —á–∏—Å–ª–∞–º–∏, —Ç–µ—Ä–º–∏–Ω–∞–º–∏",
            "screen_references": "—á—Ç–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –≤–∏–¥–Ω–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç",
            "technical_details": "–∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏",
            "context_connection": "—Å–≤—è–∑—å —Å –æ–±—â–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"
        }}
    ],
    "block_summary": "–ø–æ–¥—Ä–æ–±–Ω–æ–µ —Ä–µ–∑—é–º–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –±–ª–æ–∫–∞"
}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.05,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
                max_tokens=6000    # –£–≤–µ–ª–∏—á–∏–ª–∏ –ª–∏–º–∏—Ç –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
            )
            
            result = json.loads(response.choices[0].message.content)
            corrected_dialogue = result.get('corrected_dialogue', [])
            block_summary = result.get('block_summary', '')
            
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
            corrected_events = []
            for i, original_item in enumerate(current_block):
                if i < len(corrected_dialogue):
                    corrected = corrected_dialogue[i]
                    
                    original_event = original_item['original_event']
                    
                    # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π event —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                    new_event = TimelineEvent(
                        timestamp=original_event.timestamp,
                        type='transcript',
                        content={
                            'text': original_event.content['text'],  # –û—Ä–∏–≥–∏–Ω–∞–ª
                            'corrected_text': corrected.get('corrected_text', original_event.content['text']),
                            'speaker_id': original_event.content.get('speaker_id'),
                            'speaker_name': corrected.get('speaker'),
                            'technical_details': corrected.get('technical_details', ''),
                            'context_connection': corrected.get('context_connection', ''),
                            'duration': original_event.content.get('duration', 0),
                            'block_summary': block_summary if i == 0 else None,
                            'theme': block_theme
                        },
                        importance=original_event.importance
                    )
                    corrected_events.append(new_event)
                else:
                    # –ï—Å–ª–∏ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö - –±–µ—Ä–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                    corrected_events.append(original_item['original_event'])
            
            return corrected_events
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –±–ª–æ–∫–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return [item['original_event'] for item in current_block]
    
    def correct_transcript_group(self, transcript_events: List[TimelineEvent],
                               screenshot_events: List[TimelineEvent],
                               speakers: Dict[str, Speaker],
                               video_context: Dict) -> List[TimelineEvent]:
        """–ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç –≥—Ä—É–ø–ø—É —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –∏ —Å–æ–∑–¥–∞–µ—Ç –û–°–ú–´–°–õ–ï–ù–ù–´–ô —Ç–µ–∫—Å—Ç"""
        
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –≥–æ–≤–æ—Ä—è—â–∏–º
        speakers_texts = {}
        timeline_context = []
        
        for event in transcript_events:
            speaker_id = event.content.get('speaker_id', 'unknown')
            speaker_name = speakers.get(speaker_id, Speaker(id=speaker_id)).name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1] if speaker_id != 'unknown' else '1'}"
            
            if speaker_name not in speakers_texts:
                speakers_texts[speaker_name] = []
            
            speakers_texts[speaker_name].append(event.content['text'])
            timeline_context.append({
                'time': event.timestamp,
                'speaker': speaker_name,
                'text': event.content['text']
            })
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∏–∑—É–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
        visual_context = ""
        if screenshot_events:
            visual_context = "\n\n–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –≤ —ç—Ç–æ—Ç –ø–µ—Ä–∏–æ–¥:\n"
            for ss_event in screenshot_events:
                time_str = f"{int(ss_event.timestamp//60)}:{int(ss_event.timestamp%60):02d}"
                desc = ss_event.content.get('description', '')
                reason = ss_event.content.get('reason', '–∏–∑–º–µ–Ω–µ–Ω–∏–µ')
                visual_context += f"[{time_str}] {reason}: {desc}\n"
        
        # –°–æ–∑–¥–∞–µ–º –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –û–°–ú–´–°–õ–ï–ù–ù–û–ô –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏
        prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –≤–∏–¥–µ–æ –≤—Å—Ç—Ä–µ—á. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞—Ç—å –û–°–ú–´–°–õ–ï–ù–ù–´–ô, –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ-—Å–≤—è–∑–∞–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç.

–¢–ò–ü –í–°–¢–†–ï–ß–ò: {video_context.get('meeting_type', '–æ–±—Å—É–∂–¥–µ–Ω–∏–µ')}
–û–°–ù–û–í–ù–´–ï –¢–ï–ú–´: {', '.join(video_context.get('main_topics', []))}

–£–ß–ê–°–¢–ù–ò–ö–ò:
{chr(10).join([f"- {name}: {len(texts)} —Ä–µ–ø–ª–∏–∫" for name, texts in speakers_texts.items()])}

–ò–°–•–û–î–ù–´–ô –î–ò–ê–õ–û–ì (–ø–æ –≤—Ä–µ–º–µ–Ω–∏):
{chr(10).join([f"[{int(item['time']//60)}:{int(item['time']%60):02d}] {item['speaker']}: {item['text']}" for item in timeline_context])}
{visual_context}

–ó–ê–î–ê–ß–ò –ö–û–†–†–ï–ö–¶–ò–ò:
1. **–ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏** - –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Ç–µ—Ä–º–∏–Ω—ã
2. **–î–æ–±–∞–≤—å –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É** - —Å–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç —á–∏—Ç–∞–µ–º—ã–º
3. **–£—á—Ç–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç** - –µ—Å–ª–∏ –≥–æ–≤–æ—Ä—è—Ç "—Å–º–æ—Ç—Ä–∏—Ç–µ —Å—é–¥–∞" –∏–ª–∏ "–∫–∞–∫ –≤–∏–¥–∏—Ç–µ", –¥–æ–±–∞–≤—å –ø–æ—è—Å–Ω–µ–Ω–∏–µ [–ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ...]
4. **–°–æ—Ö—Ä–∞–Ω–∏ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—é** - –ø–æ—Ä—è–¥–æ–∫ —Ä–µ–ø–ª–∏–∫ –¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è —Ç–µ–º –∂–µ
5. **–î–æ–±–∞–≤—å –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–≤—è–∑–∫–∏** - –µ—Å–ª–∏ —Ä–µ–ø–ª–∏–∫–∏ —Å–≤—è–∑–∞–Ω—ã, –ø–æ–∫–∞–∂–∏ —ç—Ç–æ
6. **–£–±–µ—Ä–∏ –ø–æ–≤—Ç–æ—Ä—ã –∏ –ø–∞—É–∑—ã** - –æ—Å—Ç–∞–≤—å —Ç–æ–ª—å–∫–æ —Å–º—ã—Å–ª–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
7. **–î–æ–±–∞–≤—å –ø–æ—è—Å–Ω–µ–Ω–∏—è –≤ —Å–∫–æ–±–∫–∞—Ö** - –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–ª–∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã

–í–ê–ñ–ù–û: –°–æ–∑–¥–∞–π —Å–≤—è–∑–Ω—ã–π, –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –¥–∏–∞–ª–æ–≥, –∞ –Ω–µ –Ω–∞–±–æ—Ä –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ—Ä–∞–∑!

–í–µ—Ä–Ω–∏ JSON —Å –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–µ–≥–º–µ–Ω—Ç–∞–º–∏:
{{
    "corrected_segments": [
        {{
            "speaker": "–∏–º—è_–≥–æ–≤–æ—Ä—è—â–µ–≥–æ",
            "corrected_text": "–æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
            "context_explanation": "–ø–æ—è—Å–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ",
            "visual_reference": "—Å—Å—ã–ª–∫–∞ –Ω–∞ –≤–∏–∑—É–∞–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç –µ—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è"
        }}
    ],
    "overall_context": "–æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–≥–æ –≤ —ç—Ç–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ—Ç—Ä–µ–∑–∫–µ"
}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"},
                temperature=0.2,
                max_tokens=3000
            )
            
            # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
            result = json.loads(response.choices[0].message.content)
            corrected_segments = result.get('corrected_segments', [])
            overall_context = result.get('overall_context', '')
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            corrected_events = []
            for i, event in enumerate(transcript_events):
                if i < len(corrected_segments):
                    corrected = corrected_segments[i]
                    
                    # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π event
                    new_event = TimelineEvent(
                        timestamp=event.timestamp,
                        type='transcript',
                        content={
                            'text': event.content['text'],  # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
                            'corrected_text': corrected.get('corrected_text', event.content['text']),
                            'speaker_id': event.content.get('speaker_id'),
                            'speaker_name': corrected.get('speaker'),
                            'context_explanation': corrected.get('context_explanation'),
                            'visual_reference': corrected.get('visual_reference'),
                            'duration': event.content.get('duration', 0),
                            'overall_context': overall_context if i == 0 else None  # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –∫ –ø–µ—Ä–≤–æ–º—É
                        },
                        importance=event.importance
                    )
                    corrected_events.append(new_event)
                else:
                    corrected_events.append(event)
            
            return corrected_events
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            return transcript_events
    
    def structure_content(self, timeline: List[TimelineEvent], 
                         speakers: Dict[str, Speaker]) -> Dict:
        """–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–Ω—Ç –ø–æ —Ç–µ–º–∞–º –∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º"""
        
        structured = {
            'sections': [],
            'speaker_stats': defaultdict(lambda: {
                'word_count': 0,
                'segment_count': 0,
                'topics_discussed': set()
            }),
            'key_moments': []
        }
        
        current_section = {
            'start_time': 0,
            'end_time': 0,
            'topic': '–ù–∞—á–∞–ª–æ',
            'events': [],
            'speakers': set()
        }
        
        for event in timeline:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–º–µ–Ω—ã —Ç–µ–º—ã
            if event.type == 'topic_change':
                # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â—É—é —Å–µ–∫—Ü–∏—é
                if current_section['events']:
                    current_section['end_time'] = current_section['events'][-1].timestamp
                    structured['sections'].append(current_section)
                
                # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é —Å–µ–∫—Ü–∏—é
                current_section = {
                    'start_time': event.timestamp,
                    'end_time': event.timestamp,
                    'topic': event.content['topic'],
                    'events': [],
                    'speakers': set()
                }
            else:
                current_section['events'].append(event)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                if event.type == 'transcript':
                    speaker_id = event.content.get('speaker_id', 'unknown')
                    current_section['speakers'].add(speaker_id)
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–æ–≤–æ—Ä—è—â–µ–≥–æ
                    text = event.content.get('corrected_text', event.content.get('text', ''))
                    structured['speaker_stats'][speaker_id]['word_count'] += len(text.split())
                    structured['speaker_stats'][speaker_id]['segment_count'] += 1
                    structured['speaker_stats'][speaker_id]['topics_discussed'].add(
                        current_section['topic']
                    )
                
                # –û—Ç–º–µ—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
                if event.type == 'screenshot' or event.importance > 0.7:
                    structured['key_moments'].append({
                        'timestamp': event.timestamp,
                        'type': event.type,
                        'description': self.get_event_description(event)
                    })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å–µ–∫—Ü–∏—é
        if current_section['events']:
            current_section['end_time'] = current_section['events'][-1].timestamp
            structured['sections'].append(current_section)
        
        return structured
    
    def get_event_description(self, event: TimelineEvent) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è"""
        
        if event.type == 'screenshot':
            return event.content.get('description', '–°–∫—Ä–∏–Ω—à–æ—Ç')
        elif event.type == 'transcript':
            text = event.content.get('corrected_text', event.content.get('text', ''))
            return text[:100] + '...' if len(text) > 100 else text
        elif event.type == 'topic_change':
            return f"–ü–µ—Ä–µ—Ö–æ–¥ –∫ —Ç–µ–º–µ: {event.content.get('topic', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}"
        else:
            return "–°–æ–±—ã—Ç–∏–µ"
    
    def generate_chronological_report(self, structured_content: Dict,
                                    speakers: Dict[str, Speaker]) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç"""
        
        report = []
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        report.append("# –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –≤—Å—Ç—Ä–µ—á–∏\n")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö
        report.append("## –£—á–∞—Å—Ç–Ω–∏–∫–∏\n")
        for speaker_id, speaker in speakers.items():
            stats = structured_content['speaker_stats'].get(speaker_id, {})
            name = speaker.name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1]}"
            role = speaker.role or "—É—á–∞—Å—Ç–Ω–∏–∫"
            
            report.append(f"### {name} ({role})")
            report.append(f"- –°–∫–∞–∑–∞–Ω–æ —Å–ª–æ–≤: {stats.get('word_count', 0)}")
            report.append(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ø–ª–∏–∫: {stats.get('segment_count', 0)}")
            topics = list(stats.get('topics_discussed', set()))
            if topics:
                report.append(f"- –£—á–∞—Å—Ç–≤–æ–≤–∞–ª –≤ –æ–±—Å—É–∂–¥–µ–Ω–∏–∏: {', '.join(topics)}")
            report.append("")
        
        # –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
        if structured_content['key_moments']:
            report.append("\n## –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã\n")
            for moment in structured_content['key_moments'][:10]:  # –¢–æ–ø 10
                time = self.format_time(moment['timestamp'])
                report.append(f"- **{time}** - {moment['description']}")
            report.append("")
        
        # –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –ø–æ —Å–µ–∫—Ü–∏—è–º
        report.append("\n## –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç\n")
        
        for section in structured_content['sections']:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–µ–∫—Ü–∏–∏
            start_time = self.format_time(section['start_time'])
            end_time = self.format_time(section['end_time'])
            report.append(f"\n### {section['topic']} ({start_time} - {end_time})\n")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–ª–æ–∫–æ–≤ –≤ —Å–µ–∫—Ü–∏–∏
            block_themes = set()
            for event in section['events']:
                if event.type == 'transcript':
                    theme = event.content.get('theme')
                    if theme and theme != '–æ–±—â–µ–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–µ':
                        block_themes.add(theme)
            
            if block_themes:
                report.append(f"üéØ **–¢–µ–º–∞—Ç–∏–∫–∞:** {', '.join(block_themes)}\n")
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—é–º–µ –±–ª–æ–∫–æ–≤ –≤ —Å–µ–∫—Ü–∏–∏
            block_summaries = []
            for event in section['events']:
                if event.type == 'transcript':
                    block_summary = event.content.get('block_summary')
                    if block_summary and block_summary not in block_summaries:
                        block_summaries.append(block_summary)
            
            if block_summaries:
                report.append("üìã **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã:**")
                for summary in block_summaries:
                    report.append(f"  ‚Ä¢ {summary}")
                report.append("")
            
            # –°–æ–±—ã—Ç–∏—è –≤ —Å–µ–∫—Ü–∏–∏
            for event in section['events']:
                if event.type == 'transcript':
                    # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç - –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è
                    time = self.format_time(event.timestamp)
                    speaker_id = event.content.get('speaker_id', 'unknown')
                    speaker_name = event.content.get('speaker_name') or \
                                 speakers.get(speaker_id, Speaker(id=speaker_id)).name or \
                                 f"–°–ø–∏–∫–µ—Ä {speaker_id[-1] if speaker_id != 'unknown' else '1'}"
                    
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û –æ—Ç–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    corrected_text = event.content.get('corrected_text')
                    if corrected_text and corrected_text.strip():
                        report.append(f"**[{time}] {speaker_name}:** {corrected_text}")
                    else:
                        # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ
                        original_text = event.content.get('text', '').strip()
                        if original_text:
                            report.append(f"**[{time}] {speaker_name}:** {original_text}")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ù–û–í–´–ï –ø–æ–ª—è –æ—Ç –∞–≥–µ–Ω—Ç–∞
                    screen_references = event.content.get('screen_references', '')
                    if screen_references and screen_references.strip():
                        report.append(f"  üì∫ **–ù–∞ —ç–∫—Ä–∞–Ω–µ:** {screen_references}")
                    
                    technical_details = event.content.get('technical_details', '')
                    if technical_details and technical_details.strip():
                        report.append(f"  ‚öôÔ∏è **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏:** {technical_details}")
                    
                    context_connection = event.content.get('context_connection', '')
                    if context_connection and context_connection.strip():
                        report.append(f"  üîó **–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è —Å–≤—è–∑—å:** {context_connection}")
                    
                    # –°—Ç–∞—Ä—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏)
                    context_note = event.content.get('context_explanation')
                    if context_note and context_note.strip():
                        report.append(f"  üìù **–ö–æ–Ω—Ç–µ–∫—Å—Ç:** {context_note}")
                    
                    report.append("")
                    
                elif event.type == 'screenshot':
                    # –°–∫—Ä–∏–Ω—à–æ—Ç
                    time = self.format_time(event.timestamp)
                    description = event.content.get('description', '–°–∫—Ä–∏–Ω—à–æ—Ç')
                    reason = event.content.get('reason', '')
                    path = event.content.get('path', '')
                    
                    report.append(f"\nüì∏ **[{time}] –°–∫—Ä–∏–Ω—à–æ—Ç** - {reason}")
                    report.append(f"*{description}*")
                    
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64 –¥–ª—è –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è
                    if path and os.path.exists(path):
                        try:
                            with open(path, "rb") as image_file:
                                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                                ext = os.path.splitext(path)[1].lstrip('.')
                                base64_url = f"data:image/{ext};base64,{encoded_string}"
                                report.append(f"![–°–∫—Ä–∏–Ω—à–æ—Ç]({base64_url})\n")
                        except Exception as e:
                            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
                            report.append(f"![–°–∫—Ä–∏–Ω—à–æ—Ç]({path})\n")
                    else:
                        report.append("")
        
        return '\n'.join(report)
    
    def format_time(self, seconds: float) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –≤ —á–∏—Ç–∞–µ–º—ã–π –≤–∏–¥"""
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes:02d}:{secs:02d}"

    def analyze_screenshot_content(self, screenshot_path: str, timestamp: float) -> Dict:
        """–î–µ—Ç–∞–ª—å–Ω–æ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞"""
        
        try:
            # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
            with open(screenshot_path, "rb") as image_file:
                base64_image = base64.b64encode(image_file.read()).decode('utf-8')
            
            # –ü—Ä–æ–º–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            prompt = """–î–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –¥–µ–ª–æ–≤–æ–π –≤—Å—Ç—Ä–µ—á–∏.

–ò–ó–í–õ–ï–ö–ò –í–°–Å:
1. **–¢–µ–∫—Å—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ** - –¢–û–ß–ù–û —Å–∫–æ–ø–∏—Ä—É–π –≤–µ—Å—å –≤–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç
2. **–ö–æ–¥—ã/–∫–æ–º–∞–Ω–¥—ã** - –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∫–æ–¥, SQL, –∫–æ–º–∞–Ω–¥—ã - —Å–∫–æ–ø–∏—Ä—É–π —Ç–æ—á–Ω–æ
3. **–î–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü** - —á–∏—Å–ª–∞, –¥–∞—Ç—ã, —Å—Ç–∞—Ç—É—Å—ã, –∑–Ω–∞—á–µ–Ω–∏—è
4. **–°—Ö–µ–º—ã/–¥–∏–∞–≥—Ä–∞–º–º—ã** - –æ–ø–∏—à–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —ç–ª–µ–º–µ–Ω—Ç—ã
5. **UI —ç–ª–µ–º–µ–Ω—Ç—ã** - –∫–Ω–æ–ø–∫–∏, –ø–æ–ª—è, –º–µ–Ω—é —Å –∏—Ö –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
6. **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏** - –≤–µ—Ä—Å–∏–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

–í–µ—Ä–Ω–∏ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ JSON:
{
    "visible_text": "–≤–µ—Å—å –≤–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –¥–æ—Å–ª–æ–≤–Ω–æ",
    "code_snippets": ["—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞/–∫–æ–º–∞–Ω–¥ –µ—Å–ª–∏ –µ—Å—Ç—å"],
    "table_data": ["–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü/—Å–ø–∏—Å–∫–æ–≤"],
    "technical_details": ["–≤–µ—Ä—Å–∏–∏, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è"],
    "ui_elements": ["–Ω–∞–∑–≤–∞–Ω–∏—è –∫–Ω–æ–ø–æ–∫, –ø–æ–ª–µ–π, –º–µ–Ω—é"],
    "diagrams_schemas": "–æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ö–µ–º/–¥–∏–∞–≥—Ä–∞–º–º",
    "main_content_type": "—Ç–∏–ø —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ (–∫–æ–¥/–¥–æ–∫—É–º–µ–Ω—Ç/—Ç–∞–±–ª–∏—Ü–∞/–¥–∏–∞–≥—Ä–∞–º–º–∞/–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è)",
    "key_information": "—Å–∞–º–∞—è –≤–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å —ç–∫—Ä–∞–Ω–∞"
}

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ö–æ–ø–∏—Ä—É–π —Ç–µ–∫—Å—Ç –∏ –¥–∞–Ω–Ω—ã–µ –¢–û–ß–ù–û, –Ω–µ –æ–±–æ–±—â–∞–π!"""

            response = self.client.chat.completions.create(
                model="gpt-4o",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}",
                            },
                        },
                    ],
                }],
                response_format={"type": "json_object"},
                max_tokens=2000
            )
            
            result = json.loads(response.choices[0].message.content)
            logger.info(f"‚úÖ –î–µ—Ç–∞–ª—å–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å–∫—Ä–∏–Ω—à–æ—Ç –≤ {timestamp:.1f}—Å")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞: {e}")
            return {}
    
    def enhance_screenshots_with_content(self, screenshot_events: List[TimelineEvent]) -> List[TimelineEvent]:
        """–î–æ–ø–æ–ª–Ω—è–µ—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –¥–µ—Ç–∞–ª—å–Ω—ã–º –∞–Ω–∞–ª–∏–∑–æ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"""
        
        enhanced_events = []
        
        for event in screenshot_events:
            screenshot_path = event.content.get('path', '')
            
            if screenshot_path and os.path.exists(screenshot_path):
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
                detailed_content = self.analyze_screenshot_content(
                    screenshot_path, event.timestamp
                )
                
                # –°–æ–∑–¥–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ
                enhanced_content = event.content.copy()
                enhanced_content['detailed_content'] = detailed_content
                
                enhanced_event = TimelineEvent(
                    timestamp=event.timestamp,
                    type=event.type,
                    content=enhanced_content,
                    importance=event.importance
                )
                enhanced_events.append(enhanced_event)
            else:
                enhanced_events.append(event)
        
        return enhanced_events
    
    def get_screenshot_content_for_time(self, screenshot_events: List[TimelineEvent], 
                                      target_time: float, window: float = 30) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏"""
        
        relevant_screenshots = []
        
        for event in screenshot_events:
            if abs(event.timestamp - target_time) <= window:
                detailed = event.content.get('detailed_content', {})
                
                if detailed:
                    time_str = f"{int(event.timestamp//60)}:{int(event.timestamp%60):02d}"
                    content_info = f"\nüì∏ –°–ö–†–ò–ù–®–û–¢ –≤ {time_str}:\n"
                    
                    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    content_type = detailed.get('main_content_type', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    content_info += f"   –¢–∏–ø: {content_type}\n"
                    
                    # –í–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç
                    visible_text = detailed.get('visible_text', '')
                    if visible_text and visible_text.strip():
                        content_info += f"   üìÑ –¢–µ–∫—Å—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ: {visible_text[:200]}...\n"
                    
                    # –ö–æ–¥/–∫–æ–º–∞–Ω–¥—ã
                    code_snippets = detailed.get('code_snippets', [])
                    if code_snippets:
                        content_info += f"   üíª –ö–æ–¥/–∫–æ–º–∞–Ω–¥—ã: {'; '.join(code_snippets[:3])}\n"
                    
                    # –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü
                    table_data = detailed.get('table_data', [])
                    if table_data:
                        content_info += f"   üìä –î–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü: {'; '.join(table_data[:3])}\n"
                    
                    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏
                    tech_details = detailed.get('technical_details', [])
                    if tech_details:
                        content_info += f"   ‚öôÔ∏è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏: {'; '.join(tech_details[:3])}\n"
                    
                    # –ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
                    key_info = detailed.get('key_information', '')
                    if key_info and key_info.strip():
                        content_info += f"   üéØ –ö–ª—é—á–µ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {key_info}\n"
                    
                    relevant_screenshots.append(content_info)
        
        if relevant_screenshots:
            return "\n".join(relevant_screenshots)
        else:
            return ""

def integrate_chronological_processor(transcript_segments: List[Dict],
                                    screenshots: List[Tuple],
                                    video_context: Dict,
                                    api_key: str) -> Dict:
    """–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≤ –æ—Å–Ω–æ–≤–Ω–æ–π pipeline"""
    
    processor = ChronologicalTranscriptProcessor(api_key)
    result = processor.process_video_meeting(
        transcript_segments, screenshots, video_context
    )
    
    return result

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    test_segments = [
        {"text": "–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç, –¥–∞–≤–∞–π—Ç–µ –Ω–∞—á–Ω–µ–º –Ω–∞—à—É –≤—Å—Ç—Ä–µ—á—É", "start": 0, "duration": 3},
        {"text": "–ú–µ–Ω—è –∑–æ–≤—É—Ç –ò–≤–∞–Ω, —è –±—É–¥—É –≤–µ—Å—Ç–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é", "start": 3, "duration": 4},
        {"text": "–°–µ–≥–æ–¥–Ω—è –º—ã –æ–±—Å—É–¥–∏–º –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç", "start": 7, "duration": 3},
        {"text": "–£ –∫–æ–≥–æ –µ—Å—Ç—å –≤–æ–ø—Ä–æ—Å—ã?", "start": 30, "duration": 2},
        {"text": "–î–∞, —É –º–µ–Ω—è –≤–æ–ø—Ä–æ—Å –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ", "start": 35, "duration": 3},
    ]
    
    test_screenshots = [
        ("screenshot_00010s.jpg", 10, "–°–ª–∞–π–¥ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏", "presentation_slide"),
        ("screenshot_00040s.jpg", 40, "–î–∏–∞–≥—Ä–∞–º–º–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–∏—Å—Ç–µ–º—ã", "diagram"),
    ]
    
    test_context = {
        'meeting_type': 'presentation',
        'main_topics': ['–Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞', '–ø–ª–∞–Ω—ã']
    }
    
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        processor = ChronologicalTranscriptProcessor(api_key)
        result = processor.process_video_meeting(
            test_segments, test_screenshots, test_context
        )
        
        print("=== –û–¢–ß–ï–¢ ===")
        print(result['report'])
    else:
        print("–¢—Ä–µ–±—É–µ—Ç—Å—è OPENAI_API_KEY")
