#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤–∏–¥–µ–æ—Ñ–∞–π–ª–æ–≤ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–µ–π –∏ –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
"""

import os
import sys
import json
import requests
import whisper
import cv2
import numpy as np
import base64
from dotenv import load_dotenv
from openai import OpenAI
from PIL import Image
import re
import tempfile
import time # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è mlx_whisper

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
from adaptive_screenshot_extractor import AdaptiveScreenshotExtractor
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–º–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞  
from smart_transcript_extractor import SmartTranscriptExtractor
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º—É –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
from cache_manager import CacheManager

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
try:
    from chronological_transcript_processor import ChronologicalTranscriptProcessor
    CHRONOLOGICAL_AVAILABLE = True
except ImportError:
    CHRONOLOGICAL_AVAILABLE = False
    print("‚ö†Ô∏è  –•—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–µ—Ä–µ–∏–º–µ–Ω—É–π—Ç–µ chronological-transcript-processor.py –≤ chronological_transcript_processor.py")

def get_optimal_device():
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è (GPU –¥–ª—è M1/M2 Mac –∏–ª–∏ CPU)"""
    import torch
    import platform
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–ª–∞—Ç—Ñ–æ—Ä–º—É
    system = platform.system()
    machine = platform.machine()
    
    # –î–ª—è Apple Silicon Mac
    if system == "Darwin" and machine == "arm64":
        if torch.backends.mps.is_available() and torch.backends.mps.is_built():
            print("üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω Apple Silicon —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Metal Performance Shaders (MPS)")
            print("   Whisper –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return "mps"
    
    # –î–ª—è –¥—Ä—É–≥–∏—Ö —Å–∏—Å—Ç–µ–º —Å CUDA
    if torch.cuda.is_available():
        print("üöÄ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CUDA GPU")
        return "cuda"
    
    print("üíª –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU (–¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è GPU)")
    return "cpu"

def load_whisper_optimized(model_size="base"):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Whisper —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞"""
    import torch
    
    device = get_optimal_device()
    
    print(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ Whisper ({model_size}) –Ω–∞ {device}...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model = whisper.load_model(model_size, device=device)
    
    # –î–ª—è Apple Silicon —Å MPS –Ω—É–∂–Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if device == "mps":
        # Whisper –º–æ–∂–µ—Ç –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å MPS, –ø–æ—ç—Ç–æ–º—É –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–º–µ—à–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥
        print("   –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Apple Silicon...")
        # –ú–æ–¥–µ–ª—å –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–∞ CPU, –Ω–æ –æ–ø–µ—Ä–∞—Ü–∏–∏ –±—É–¥—É—Ç —É—Å–∫–æ—Ä–µ–Ω—ã —á–µ—Ä–µ–∑ Metal
        # –≠—Ç–æ —Å–≤—è–∑–∞–Ω–æ —Å –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—è–º–∏ —Ä–∞–±–æ—Ç—ã Whisper
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ç–æ–∫–∏ –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã –Ω–∞ M1 Max
        torch.set_num_threads(8)  # 8 –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã—Ö —è–¥–µ—Ä –Ω–∞ M1 Max
        
        # –í–∫–ª—é—á–∞–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ Metal
        if hasattr(torch.backends, 'mps'):
            torch.backends.mps.enable_fallback = True
    
    elif device == "cuda":
        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ GPU
        model = model.to(device)
        print(f"   –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –Ω–∞ GPU")
    
    return model, device

def create_transcript_with_mlx_whisper(audio_file, model_size="base", video_path=None, cache_manager=None):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø–æ–º–æ—â—å—é MLX Whisper (GPU-—É—Å–∫–æ—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Apple Silicon)"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if cache_manager and video_path:
        cached_transcript = cache_manager.get_cached_transcript(video_path)
        if cached_transcript:
            return cached_transcript
    
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º mlx_whisper
        import mlx_whisper
        
        print(f"üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ MLX Whisper ({model_size}) —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º...")
        print("üí° –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Apple Silicon")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞
        model_path = f"mlx-community/whisper-{model_size}-mlx"
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –º–æ–¥–µ–ª–µ–π
        model_paths = {
            "tiny": "mlx-community/whisper-tiny-mlx",
            "base": "mlx-community/whisper-base-mlx", 
            "small": "mlx-community/whisper-small-mlx",
            "medium": "mlx-community/whisper-medium-mlx",
            "large": "mlx-community/whisper-large-v3-mlx",
            "large-v3": "mlx-community/whisper-large-v3-mlx"
        }
        
        if model_size in model_paths:
            model_path = model_paths[model_size]
        
        print(f"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_path}")
        print("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –∏ –ª—É—á—à–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º —Å MLX Whisper —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        start_time = time.time()
        result = mlx_whisper.transcribe(
            audio_file,
            path_or_hf_repo=model_path,
            language="ru",
            verbose=True
        )
        
        elapsed_time = time.time() - start_time
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {elapsed_time:.1f} —Å–µ–∫—É–Ω–¥")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        segments = result.get("segments", [])
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã –≤ –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        merged_segments = []
        current_segment = None
        min_segment_duration = 10.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
        for segment in segments:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏–ª–∏ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            if not segment.get("text", "").strip() or len(segment.get("text", "").strip()) < 3:
                continue
                
            if current_segment is None:
                current_segment = {
                    "text": segment["text"],
                    "start": segment["start"],
                    "end": segment["end"]
                }
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å —Ç–µ–∫—É—â–∏–º —Å–µ–≥–º–µ–Ω—Ç–æ–º
                duration = segment["end"] - current_segment["start"]
                if duration < min_segment_duration:
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º
                    current_segment["text"] += " " + segment["text"]
                    current_segment["end"] = segment["end"]
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–∏–π –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                    merged_segments.append({
                        "text": current_segment["text"].strip(),
                        "start": current_segment["start"],
                        "duration": current_segment["end"] - current_segment["start"]
                    })
                    current_segment = {
                        "text": segment["text"],
                        "start": segment["start"],
                        "end": segment["end"]
                    }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
        if current_segment:
            merged_segments.append({
                "text": current_segment["text"].strip(),
                "start": current_segment["start"],
                "duration": current_segment["end"] - current_segment["start"]
            })
        
        print(f"üìä –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(segments)} –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ {len(merged_segments)} –¥–ª–∏–Ω–Ω—ã—Ö")
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –∏ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
        filtered_segments = filter_repetitive_segments(merged_segments)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ —Ç–∏–ø–∞ "Zhi Zhi Zhi"
        final_segments = []
        for seg in filtered_segments:
            text = seg["text"]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
            words = text.split()
            if len(words) > 3:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å–æ—Å—Ç–æ–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∏–∑ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
                unique_words = set(words)
                if len(unique_words) > len(words) * 0.2:  # –•–æ—Ç—è –±—ã 20% —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤
                    final_segments.append(seg)
            elif len(text.strip()) > 10:  # –ò–ª–∏ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π
                final_segments.append(seg)
        
        # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
        full_text = " ".join([seg["text"] for seg in final_segments])
        
        print(f"üéØ –§–∏–Ω–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–≥–º–µ–Ω—Ç–æ–≤: {len(final_segments)}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
        if cache_manager and video_path:
            cache_manager.save_transcript_cache(video_path, final_segments, full_text)
        
        return final_segments, full_text
        
    except ImportError:
        print("‚ö†Ô∏è mlx_whisper –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Whisper...")
        return create_transcript_with_whisper(audio_file, model_size, video_path, cache_manager)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ MLX Whisper: {str(e)}")
        print("‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Whisper...")
        return create_transcript_with_whisper(audio_file, model_size, video_path, cache_manager)

def create_transcript_with_whisper(audio_file, model_size="base", video_path=None, cache_manager=None):
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å –ø–æ–º–æ—â—å—é Whisper"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if cache_manager and video_path:
        cached_transcript = cache_manager.get_cached_transcript(video_path)
        if cached_transcript:
            return cached_transcript
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        model, device = load_whisper_optimized(model_size)
        
        print("üéØ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ...")
        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä—É—Å—Å–∫–æ–π —Ä–µ—á–∏
        # –î–æ–±–∞–≤–ª—è–µ–º fp16 –¥–ª—è M1 Max –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        use_fp16 = device == "mps" or device == "cuda"
        
        result = model.transcribe(
            audio_file, 
            language="ru",
            initial_prompt="–≠—Ç–æ –¥–µ–ª–æ–≤–∞—è –≤—Å—Ç—Ä–µ—á–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ —Å –æ–±—Å—É–∂–¥–µ–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è –∏ –ø–ª–∞–Ω–æ–≤.",
            temperature=0.0,  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            beam_size=5,      # –ë–æ–ª—å—à–µ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ª—É—á—à–µ–≥–æ
            best_of=5,        # –í—ã–±–∏—Ä–∞—Ç—å –ª—É—á—à–∏–π –∏–∑ 5 –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
            compression_ratio_threshold=2.4,  # –§–∏–ª—å—Ç—Ä –æ—Ç –±–µ—Å—Å–º—ã—Å–ª–∏—Ü—ã
            logprob_threshold=-1.0,  # –§–∏–ª—å—Ç—Ä –ø–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            no_speech_threshold=0.6,   # –ü–æ—Ä–æ–≥ —Ç–∏—à–∏–Ω—ã
            fp16=use_fp16     # –ò—Å–ø–æ–ª—å–∑—É–µ–º fp16 –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ GPU/MPS
        )
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏
        segments = []
        for segment in result["segments"]:
            segments.append({
                "text": segment["text"],
                "start": segment["start"],
                "duration": segment["end"] - segment["start"]
            })
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–µ–≥–º–µ–Ω—Ç—ã
        original_count = len(segments)
        segments = filter_repetitive_segments(segments)
        
        if len(segments) < original_count:
            print(f"‚ö†Ô∏è  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ {original_count - len(segments)} –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤")
            # –ü–µ—Ä–µ—Å–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–µ–≥–º–µ–Ω—Ç–æ–≤
            full_text = " ".join([s['text'] for s in segments if s.get('text')])
        else:
            full_text = result["text"]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
        if cache_manager and video_path:
            cache_manager.save_transcript_cache(video_path, segments, full_text)
        
        return segments, full_text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ —Å Whisper: {e}")
        return None, None

def create_clean_transcript_with_whisper(audio_file, model_size="base", video_path=None, cache_manager=None, chunk_duration=180):
    """–°–æ–∑–¥–∞–Ω–∏–µ —á–∏—Å—Ç–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∫—Ä—É–ø–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if cache_manager and video_path:
        cached_transcript = cache_manager.get_cached_transcript(video_path)
        if cached_transcript and isinstance(cached_transcript, tuple) and len(cached_transcript) > 1:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
            return cached_transcript[1]
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ –¥–ª—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        model, device = load_whisper_optimized(model_size)
        
        print(f"üéß –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ –±–ª–æ–∫–∞–º–∏ –ø–æ {chunk_duration} —Å–µ–∫—É–Ω–¥...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –∏ –ø–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        import librosa
        audio_data, sr = librosa.load(audio_file, sr=16000)
        duration = len(audio_data) / sr
        
        full_transcript_parts = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—É–¥–∏–æ –±–ª–æ–∫–∞–º–∏
        for start_time in range(0, int(duration), chunk_duration):
            end_time = min(start_time + chunk_duration, duration)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—Ç—å –∞—É–¥–∏–æ
            start_sample = int(start_time * sr)
            end_sample = int(end_time * sr)
            chunk_audio = audio_data[start_sample:end_sample]
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –±–ª–æ–∫–∞
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                import soundfile as sf
                sf.write(tmp_file.name, chunk_audio, sr)
                
                # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –±–ª–æ–∫
                print(f"  ‚è±Ô∏è  –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–∞ {int(start_time/60)}:{start_time%60:02d} - {int(end_time/60)}:{end_time%60:02d}")
                result = model.transcribe(
                    tmp_file.name,
                    language="ru",
                    initial_prompt="–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –≤—Å—Ç—Ä–µ—á–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. "
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç –±–ª–æ–∫–∞
                if result['text'].strip():
                    full_transcript_parts.append(result['text'].strip())
                
                # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                os.unlink(tmp_file.name)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
        full_transcript = "\n\n".join(full_transcript_parts)
        
        print(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω: {len(full_transcript)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if cache_manager and video_path:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å –æ–±—ã—á–Ω—ã–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–º
            cache_manager.save_transcript_cache(video_path, [], full_transcript)
        
        return full_transcript
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —á–∏—Å—Ç–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞: {e}")
        import traceback
        traceback.print_exc()
        return None

def extract_audio_from_video(video_path, output_dir="temp", cache_manager=None):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if cache_manager:
        cached_audio = cache_manager.get_cached_audio(video_path)
        if cached_audio:
            return cached_audio
    
    try:
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        audio_path = os.path.join(output_dir, f"{video_name}_audio.wav")
        
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ –∏–∑ {video_path}...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º cv2 –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ (–ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–±)
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ—Ñ–∞–π–ª: {video_path}")
        
        # –î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg —á–µ—Ä–µ–∑ os.system
        import subprocess
        
        # –ö–æ–º–∞–Ω–¥–∞ ffmpeg –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ
        cmd = [
            "ffmpeg", "-y",  # -y –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞
            "-i", video_path,
            "-vn",  # –Ω–µ –≤–∫–ª—é—á–∞—Ç—å –≤–∏–¥–µ–æ
            "-acodec", "pcm_s16le",  # –∫–æ–¥–µ–∫ –¥–ª—è wav
            "-ar", "16000",  # —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ 16kHz (–æ–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è Whisper)
            "-ac", "1",  # –º–æ–Ω–æ
            audio_path
        ]
        
        print("–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞—É–¥–∏–æ...")
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"–û—à–∏–±–∫–∞ ffmpeg: {result.stderr}")
            # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ moviepy
            try:
                from moviepy.editor import VideoFileClip
                print("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ moviepy...")
                video_clip = VideoFileClip(video_path)
                audio_clip = video_clip.audio
                audio_clip.write_audiofile(audio_path, verbose=False, logger=None)
                audio_clip.close()
                video_clip.close()
            except ImportError:
                print("–î–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞—É–¥–∏–æ –Ω—É–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å ffmpeg –∏–ª–∏ moviepy")
                print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞: pip install moviepy")
                return None
        
        if os.path.exists(audio_path):
            print(f"–ê—É–¥–∏–æ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ: {audio_path}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
            if cache_manager:
                cached_path = cache_manager.save_audio_cache(video_path, audio_path)
                return cached_path
            
            return audio_path
        else:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ")
            return None
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {e}")
        return None

def filter_repetitive_segments(segments, max_repetitions=5):
    """–§–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–µ–≥–º–µ–Ω—Ç—ã –∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ Whisper"""
    if not segments:
        return segments
    
    filtered_segments = []
    repetition_count = 0
    last_text = None
    
    for segment in segments:
        segment_text = segment.get('text', '').strip()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ
        if segment_text == last_text and len(segment_text) < 20:  # –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–∑—ã
            repetition_count += 1
            if repetition_count > max_repetitions:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–π—Å—è —Å–µ–≥–º–µ–Ω—Ç
        else:
            repetition_count = 0
            last_text = segment_text
        
        filtered_segments.append(segment)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —É–¥–∞–ª–∏–ª–∏ –ª–∏ –º—ã —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ
    if len(filtered_segments) < len(segments) * 0.5:
        print(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ Whisper: {len(segments) - len(filtered_segments)} –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Å–µ–≥–º–µ–Ω—Ç–æ–≤ —É–¥–∞–ª–µ–Ω–æ")
    
    return filtered_segments

def extract_screenshots_traditional(video_path, output_dir, interval=30, api_key=None):
    """–¢—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # –û—Ç–∫—Ä—ã–≤–∞–µ–º –≤–∏–¥–µ–æ —Ñ–∞–π–ª
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ {video_path}")
        return []
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    frame_interval = int(fps * interval)  # –ö–∞–¥—Ä—ã —á–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–µ interval —Å–µ–∫—É–Ω–¥
    
    print(f"–ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: –≤—Å–µ–≥–æ {total_frames} –∫–∞–¥—Ä–æ–≤, FPS: {fps}, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {duration:.1f} —Å–µ–∫")
    print(f"–ë—É–¥–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–æ ~{int(duration // interval)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
    
    saved_screenshots = []
    frame_count = 0
    screenshot_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä –∫–∞–∂–¥—ã–µ interval —Å–µ–∫—É–Ω–¥
        if frame_count % frame_interval == 0:
            current_time = frame_count / fps
            timestamp = int(current_time)
            
            # –ò–º—è —Ñ–∞–π–ª–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
            screenshot_path = f"{output_dir}/screenshot_{timestamp:05d}s.jpg"
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–¥—Ä —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º
            cv2.imwrite(screenshot_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 95])
            
            description = None
            if api_key:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç —Å –ø–æ–º–æ—â—å—é GPT-4V
                description = analyze_screenshot_with_gpt4v(screenshot_path, api_key)
            
            saved_screenshots.append((screenshot_path, timestamp, description, "periodic"))
            screenshot_count += 1
            
            minutes = timestamp // 60
            seconds = timestamp % 60
            print(f"–°–∫—Ä–∏–Ω—à–æ—Ç {screenshot_count}: {minutes}:{seconds:02d} - {screenshot_path}")
        
        frame_count += 1
    
    cap.release()
    print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(saved_screenshots)} —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
    return saved_screenshots

def extract_screen_content(image_path, api_key):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ–¥, —Ç–∞–±–ª–∏—Ü—ã —Å —ç–∫—Ä–∞–Ω–∞"""
    try:
        # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
        client = OpenAI(api_key=api_key)
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        prompt = """–ò–∑–≤–ª–µ–∫–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞:

1. **–ö–æ–¥** - –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∫–æ–¥, —Å–∫–æ–ø–∏—Ä—É–π –µ–≥–æ —Ç–æ—á–Ω–æ
2. **–¢–µ–∫—Å—Ç** - –≤–µ—Å—å —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —ç–∫—Ä–∞–Ω–µ
3. **–¢–∞–±–ª–∏—Ü—ã** - –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—á–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
4. **–î–∏–∞–≥—Ä–∞–º–º—ã** - –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ö–µ–º –∏ –¥–∏–∞–≥—Ä–∞–º–º
5. **UI —ç–ª–µ–º–µ–Ω—Ç—ã** - –Ω–∞–∑–≤–∞–Ω–∏—è –∫–Ω–æ–ø–æ–∫, –º–µ–Ω—é, –ø–æ–ª–µ–π

–í–µ—Ä–Ω–∏ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ:
{
    "content_type": "code/text/table/diagram/ui",
    "extracted_text": "–≤–µ—Å—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
    "code_snippets": ["—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∫–æ–¥–∞ –µ—Å–ª–∏ –µ—Å—Ç—å"],
    "table_data": "–¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü –µ—Å–ª–∏ –µ—Å—Ç—å",
    "ui_elements": ["—ç–ª–µ–º–µ–Ω—Ç—ã –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"],
    "description": "–∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ"
}

–í–ê–ñ–ù–û: –ò–∑–≤–ª–µ–∫–∞–π —Ç–µ–∫—Å—Ç –¢–û–ß–ù–û –∫–∞–∫ –Ω–∞–ø–∏—Å–∞–Ω–æ, –≤–∫–ª—é—á–∞—è –∫–æ–¥ –∏ –¥–∞–Ω–Ω—ã–µ."""
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT-4V
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                        },
                    },
                ],
            }],
            response_format={"type": "json_object"},
            max_tokens=1500
        )
        
        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = json.loads(response.choices[0].message.content)
        return result
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —ç–∫—Ä–∞–Ω–∞: {e}")
        return None

def analyze_screenshot_with_gpt4v(image_path, api_key):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç —Å –ø–æ–º–æ—â—å—é GPT-4V"""
    try:
        # –ö–æ–¥–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
        with open(image_path, "rb") as image_file:
            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
        client = OpenAI(api_key=api_key)
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
        prompt = """–û–ø–∏—à–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —ç—Ç–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –∏–∑ –≤–∏–¥–µ–æ –≤—Å—Ç—Ä–µ—á–∏. –í–∫–ª—é—á–∏:
1. –ß—Ç–æ –≤–∏–¥–Ω–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ (–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å, –¥–æ–∫—É–º–µ–Ω—Ç—ã, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è, –∫–æ–¥ –∏ —Ç.–¥.)
2. –û—Å–Ω–æ–≤–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
3. –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –∫—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ–¥–∞–π –µ–≥–æ —Å—É—Ç—å
4. –û–±—â–∞—è —Ç–µ–º–∞/–∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥—è—â–µ–≥–æ

–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."""
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ GPT-4V
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                        },
                    },
                ],
            }],
            max_tokens=500
        )
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        description = response.choices[0].message.content.strip()
        return description
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ —Å GPT-4V: {e}")
        return None

def analyze_content_with_gpt(transcript_text, api_key, video_title="–õ–æ–∫–∞–ª—å–Ω–æ–µ –≤–∏–¥–µ–æ", screenshots_info=None, video_path=None, cache_manager=None):
    """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ —Å –ø–æ–º–æ—â—å—é GPT"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
    if cache_manager and video_path:
        cached_analysis = cache_manager.get_cached_analysis(video_path, "basic")
        if cached_analysis:
            return cached_analysis
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞—Ö –≤ –ø—Ä–æ–º–ø—Ç
    screenshots_summary = ""
    if screenshots_info and len(screenshots_info) > 0:
        screenshots_summary = "\n\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–∞—Ö –≤–∏–¥–µ–æ (–Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤):\n"
        for i, (_, timestamp, description, reason) in enumerate(screenshots_info[:10]):  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10
            if description:
                minutes = int(timestamp // 60)
                seconds = int(timestamp % 60)
                screenshots_summary += f"\n{minutes}:{seconds:02d} - {description[:200]}..."
    
    prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤–∏–¥–µ–æ "{video_title}".
    
    –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:
    {transcript_text}
    {screenshots_summary}
    
    –°–æ–∑–¥–∞–π —Å–ª–µ–¥—É—é—â–µ–µ:
    1. –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ (3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
    2. –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–∑–∏—Å—ã –∏ –∫–ª—é—á–µ–≤—ã–µ –º—ã—Å–ª–∏ (8-10 –ø—É–Ω–∫—Ç–æ–≤ –≤ –≤–∏–¥–µ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞)
    3. –í–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã (–µ—Å–ª–∏ –±—ã–ª–∏ –ø–æ–∫–∞–∑–∞–Ω—ã –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏, –∫–æ–¥, –¥–µ–º–æ - –æ–ø–∏—à–∏ —á—Ç–æ –∏–º–µ–Ω–Ω–æ)
    4. –í—ã–≤–æ–¥—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
    """
    
    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        payload = {
            "model": "gpt-4o-mini",
            "messages": [
                {"role": "system", "content": "–¢—ã - –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤–∏–¥–µ–æ–∫–æ–Ω—Ç–µ–Ω—Ç–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –≤—ã–¥–µ–ª—è—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏ –∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è."},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.1,
            "max_tokens": 2000
        }
        
        response = requests.post(
            "https://api.openai.com/v1/chat/completions", 
            headers=headers, 
            json=payload
        )
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            analysis = result["choices"][0]["message"]["content"]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à, –µ—Å–ª–∏ –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω
            if cache_manager and video_path:
                cache_manager.save_analysis_cache(video_path, analysis, "basic")
            
            return analysis
        else:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {result}")
            return None
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞: {e}")
        return None

def get_image_base64(image_path):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Å—Ç—Ä–æ–∫—É base64 –¥–ª—è –≤—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏—è –≤ markdown"""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            ext = os.path.splitext(image_path)[1].lstrip('.')
            return f"data:image/{ext};base64,{encoded_string}"
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64: {e}")
        return None

def save_chronological_results(video_name, chronological_data, output_dir="results"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–û–ì–û —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞ —Å–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏ –≤ –¥–∏–∞–ª–æ–≥–µ"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    speakers = chronological_data['speakers']
    timeline = chronological_data['timeline']
    structured_content = chronological_data['structured_content']
    report = chronological_data['report']
    
    # –°–æ–∑–¥–∞–µ–º –ï–î–ò–ù–£–Æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ª–∏–Ω–∏—é —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ —Å–æ–±—ã—Ç–∏—è–º–∏
    unified_timeline = []
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    for event in timeline:
        unified_timeline.append(event)
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —Å–æ–±—ã—Ç–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏
    unified_timeline.sort(key=lambda x: x.timestamp)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
    md_file = f"{output_dir}/{video_name}_INTEGRATED_chronological.md"
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(f"# üé¨ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô –∞–Ω–∞–ª–∏–∑ –≤—Å—Ç—Ä–µ—á–∏: {video_name}\n\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫—Ä–∞—Ç–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É—á–∞—Å—Ç–Ω–∏–∫–∞—Ö
        f.write("## üë• –£—á–∞—Å—Ç–Ω–∏–∫–∏\n\n")
        for speaker_id, speaker in speakers.items():
            name = speaker.name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1]}"
            role = speaker.role or "—É—á–∞—Å—Ç–Ω–∏–∫"
            f.write(f"- **{name}** ({role})")
            if speaker.characteristics:
                f.write(f" - {', '.join(speaker.characteristics[:2])}")
            f.write("\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∞–Ω–∞–ª–∏–∑
        f.write(f"\n## üìã –ö—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑\n\n{report}\n\n")
        
        # –ì–õ–ê–í–ù–ê–Ø –ß–ê–°–¢–¨ - –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–ê–Ø –í–†–ï–ú–ï–ù–ù–ê–Ø –õ–ò–ù–ò–Ø
        f.write("## üéØ –•–†–û–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –•–û–î –í–°–¢–†–ï–ß–ò (—Å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏)\n\n")
        f.write("*–í—Å–µ —Å–æ–±—ã—Ç–∏—è —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ. –°–∫—Ä–∏–Ω—à–æ—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏–ª–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –≤ –º–æ–º–µ–Ω—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.*\n\n")
        f.write("---\n\n")
        
        current_topic = "–ù–∞—á–∞–ª–æ –≤—Å—Ç—Ä–µ—á–∏"
        last_speaker = None
        screenshot_counter = 1
        
        for event in unified_timeline:
            minutes = int(event.timestamp // 60)
            seconds = int(event.timestamp % 60)
            timestamp_str = f"{minutes}:{seconds:02d}"
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–º–µ–Ω—ã —Ç–µ–º—ã
            if event.type == 'topic_change':
                current_topic = event.content.get('topic', '–ù–æ–≤–∞—è —Ç–µ–º–∞')
                f.write(f"\n\n### üìå [{timestamp_str}] –¢–ï–ú–ê: {current_topic.upper()}\n\n")
                continue
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
            elif event.type == 'transcript':
                speaker_id = event.content.get('speaker_id', 'unknown')
                speaker_name = event.content.get('speaker_name')
                
                if not speaker_name:
                    speaker_obj = speakers.get(speaker_id)
                    speaker_name = speaker_obj.name if speaker_obj else f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1] if speaker_id != 'unknown' else '1'}"
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –µ—Å–ª–∏ –µ—Å—Ç—å
                text = event.content.get('corrected_text', event.content.get('text', ''))
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≥—Ä—É–ø–ø—ã, –µ—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Ä–µ–ø–ª–∏–∫–∞ –≤ –≥—Ä—É–ø–ø–µ
                overall_context = event.content.get('overall_context')
                if overall_context:
                    f.write(f"\nüí° **–ö–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–º–µ–Ω—Ç–∞:** *{overall_context}*\n\n")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–º–µ–Ω—É –≥–æ–≤–æ—Ä—è—â–µ–≥–æ –±–æ–ª–µ–µ –∑–∞–º–µ—Ç–Ω–æ
                if speaker_name != last_speaker:
                    f.write(f"\n**[{timestamp_str}] {speaker_name}:** {text}")
                    last_speaker = speaker_name
                else:
                    f.write(f" {text}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è
                context_explanation = event.content.get('context_explanation')
                if context_explanation:
                    f.write(f" *[{context_explanation}]*")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –≤–∏–∑—É–∞–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                visual_reference = event.content.get('visual_reference')
                if visual_reference:
                    f.write(f" üëÅÔ∏è *{visual_reference}*")
                
                f.write("\n")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ - –í–°–¢–†–ê–ò–í–ê–ï–ú –ü–†–Ø–ú–û –í –î–ò–ê–õ–û–ì
            elif event.type == 'screenshot':
                reason = event.content.get('reason', '–í–∞–∂–Ω—ã–π –º–æ–º–µ–Ω—Ç')
                description = event.content.get('description', '')
                image_path = event.content.get('path', '')
                
                f.write(f"\n\nüì∏ **[{timestamp_str}] –°–ö–†–ò–ù–®–û–¢ #{screenshot_counter}: {reason}**\n\n")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ü–†–Ø–ú–û –í –ü–û–¢–û–ö
                if image_path and os.path.exists(image_path):
                    image_base64 = get_image_base64(image_path)
                    if image_base64:
                        f.write(f"![–°–∫—Ä–∏–Ω—à–æ—Ç {screenshot_counter}]({image_base64})\n\n")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≥–æ, —á—Ç–æ –Ω–∞ —ç–∫—Ä–∞–Ω–µ
                if description:
                    f.write(f"*–ù–∞ —ç–∫—Ä–∞–Ω–µ: {description}*\n\n")
                else:
                    f.write(f"*–í–∏–∑—É–∞–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞ —ç–∫—Ä–∞–Ω–µ –≤ –º–æ–º–µ–Ω—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞*\n\n")
                
                screenshot_counter += 1
                f.write("---\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        f.write(f"\n\n## üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Å—Ç—Ä–µ—á–∏\n\n")
        total_duration = max([e.timestamp for e in unified_timeline]) if unified_timeline else 0
        total_screenshots = len([e for e in unified_timeline if e.type == 'screenshot'])
        total_topics = len([e for e in unified_timeline if e.type == 'topic_change'])
        
        f.write(f"- **–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:** {int(total_duration // 60)}:{int(total_duration % 60):02d}\n")
        f.write(f"- **–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤:** {len(speakers)}\n")
        f.write(f"- **–°–∫—Ä–∏–Ω—à–æ—Ç–æ–≤:** {total_screenshots}\n")
        f.write(f"- **–°–º–µ–Ω —Ç–µ–º—ã:** {total_topics}\n")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
        f.write(f"\n### –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤:\n")
        for speaker_id, speaker in speakers.items():
            name = speaker.name or f"–£—á–∞—Å—Ç–Ω–∏–∫ {speaker_id[-1]}"
            segments_count = len(speaker.voice_segments) if speaker.voice_segments else 0
            f.write(f"- **{name}:** {segments_count} —Ä–µ–ø–ª–∏–∫\n")
    
    print(f"üéØ –ò–ù–¢–ï–ì–†–ò–†–û–í–ê–ù–ù–´–ô —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {md_file}")
    
    # –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º JSON —Å –ø–æ–¥—Ä–æ–±–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    json_file = f"{output_dir}/{video_name}_integrated_data.json"
    json_data = {
        "video_name": video_name,
        "total_duration": max([e.timestamp for e in unified_timeline]) if unified_timeline else 0,
        "speakers": {
            speaker_id: {
                "name": speaker.name,
                "role": speaker.role,
                "characteristics": speaker.characteristics,
                "segments_count": len(speaker.voice_segments) if speaker.voice_segments else 0
            }
            for speaker_id, speaker in speakers.items()
        },
        "timeline_events_count": {
            "total": len(unified_timeline),
            "transcript": len([e for e in unified_timeline if e.type == 'transcript']),
            "screenshots": len([e for e in unified_timeline if e.type == 'screenshot']),
            "topic_changes": len([e for e in unified_timeline if e.type == 'topic_change'])
        },
        "report": report
    }
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(json_data, f, ensure_ascii=False, indent=4)
    
    return md_file, json_file

def save_results(video_name, transcript_segments, full_transcript, analysis, screenshots=None, output_dir="results"):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown
    md_file = f"{output_dir}/{video_name}_analysis.md"
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(f"# –ê–Ω–∞–ª–∏–∑ –≤–∏–¥–µ–æ: {video_name}\n\n")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–∏–∑
        if analysis:
            f.write(analysis)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if screenshots and len(screenshots) > 0:
            f.write("\n\n## –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤–∏–¥–µ–æ\n\n")
            
            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –ø–æ —Ç–∏–ø—É
            ai_screenshots = [s for s in screenshots if s[3] != "periodic"]
            periodic_screenshots = [s for s in screenshots if s[3] == "periodic"]
            
            if ai_screenshots:
                f.write("### ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã\n\n")
                for i, (image_path, timestamp, description, reason) in enumerate(ai_screenshots):
                    minutes = int(timestamp // 60)
                    seconds = int(timestamp % 60)
                    f.write(f"#### {minutes}:{seconds:02d} - {reason}\n\n")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ base64
                    image_base64 = get_image_base64(image_path)
                    if image_base64:
                        f.write(f"![–°–∫—Ä–∏–Ω—à–æ—Ç]({image_base64})\n\n")
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if description:
                        f.write(f"{description}\n\n")
                    
                    f.write("---\n\n")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –≤ –∫–æ–Ω—Ü–µ, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if periodic_screenshots and len(ai_screenshots) < 5:
                f.write("### üì∏ –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã\n\n")
                for i, (image_path, timestamp, description, _) in enumerate(periodic_screenshots[:5]):
                    minutes = int(timestamp // 60)
                    seconds = int(timestamp % 60)
                    f.write(f"#### {minutes}:{seconds:02d}\n\n")
                    
                    image_base64 = get_image_base64(image_path)
                    if image_base64:
                        f.write(f"![–°–∫—Ä–∏–Ω—à–æ—Ç]({image_base64})\n\n")
                    
                    if description:
                        f.write(f"{description}\n\n")
                    
                    f.write("---\n\n")
        
        f.write("\n\n## –ü–æ–ª–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç\n\n")
        f.write(full_transcript)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–µ–≥–º–µ–Ω—Ç—ã
        if transcript_segments and len(transcript_segments) > 0:
            f.write("\n\n## –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏\n\n")
            for segment in transcript_segments:
                start_time = segment['start']
                minutes = int(start_time // 60)
                seconds = int(start_time % 60)
                f.write(f"**{minutes}:{seconds:02d}** - {segment['text']}\n\n")
        elif not transcript_segments:
            f.write("\n\n---\n*–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω –≤ —á–∏—Å—Ç–æ–º —Ä–µ–∂–∏–º–µ –±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫*")
    
    print(f"–ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ Markdown —Ñ–∞–π–ª: {md_file}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    json_file = f"{output_dir}/{video_name}_analysis.json"
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è JSON
    screenshots_data = []
    if screenshots:
        for image_path, timestamp, description, reason in screenshots:
            screenshots_data.append({
                "image_path": image_path,
                "timestamp": timestamp,
                "description": description,
                "reason": reason
            })
    
    results = {
        "video_name": video_name,
        "full_transcript": full_transcript,
        "transcript_segments": transcript_segments,
        "analysis": analysis,
        "screenshots": screenshots_data
    }
    
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=4)
        
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ JSON: {json_file}")
    
    return md_file, json_file

def main():
    load_dotenv()
    
    if len(sys.argv) < 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
        print("  python updated_video_analyzer.py <–ø—É—Ç—å_–∫_–≤–∏–¥–µ–æ> [–æ–ø—Ü–∏–∏]")
        print("\n–û–ø—Ü–∏–∏:")
        print("  --whisper-model MODEL      –ú–æ–¥–µ–ª—å Whisper (tiny, base, small, medium, large)")
        print("  --screenshot-interval N    –ò–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Å–∫—Ä–∏–Ω—à–æ—Ç–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)")
        print("  --no-screenshots          –ù–µ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç—ã")
        print("  --smart-screenshots       –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ò–ò –¥–ª—è —É–º–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤")
        print("  --screenshot-mode MODE    –†–µ–∂–∏–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: 'periodic', 'smart', 'transcript', 'both' (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: transcript)")
        print("  --clean-transcript [N]     –°–æ–∑–¥–∞—Ç—å —á–∏—Å—Ç—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –±–ª–æ–∫–∞–º–∏ –ø–æ N —Å–µ–∫—É–Ω–¥ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 120)")
        print("  --basic-mode              –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º (–±–µ–∑ –∞–≥–µ–Ω—Ç–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π)")
        print("  --output DIR              –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: results)")
        print("  --clear-cache             –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –¥–ª—è —ç—Ç–æ–≥–æ –≤–∏–¥–µ–æ")
        print("  --force-refresh           –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ (–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à)")
        print("  --cache-status            –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ç—É—Å –∫—ç—à–∞ –∏ –≤—ã–π—Ç–∏")
        print("  --test-first-10min        –û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –º–∏–Ω—É—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        print("\n–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é:")
        print("  ü§ñ –ê–ì–ï–ù–¢–ù–´–ô –†–ï–ñ–ò–ú - –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π")
        print("\n–ü—Ä–∏–º–µ—Ä—ã:")
        print("  python updated_video_analyzer.py video.mp4 --test-first-10min")
        print("  python updated_video_analyzer.py video.mp4 --clean-transcript 180 --no-screenshots")
        print("  python updated_video_analyzer.py video.mp4 --clean-transcript --whisper-model large")
        sys.exit(1)
    
    video_path = sys.argv[1]
    
    # –ü–∞—Ä—Å–∏–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã
    whisper_model = "base"
    screenshot_interval = 30
    extract_screenshots_flag = True
    screenshot_mode = "transcript"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
    clean_transcript = False  # –§–ª–∞–≥ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞
    chunk_duration = 120  # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–ª–æ–∫–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    basic_mode = False  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º!
    output_dir = "results"
    clear_cache = False
    force_refresh = False
    cache_status_only = False
    test_first_10min = False
    
    i = 2
    while i < len(sys.argv):
        if sys.argv[i] == "--whisper-model" and i + 1 < len(sys.argv):
            whisper_model = sys.argv[i + 1]
            i += 2
        elif sys.argv[i] == "--screenshot-interval" and i + 1 < len(sys.argv):
            screenshot_interval = int(sys.argv[i + 1])
            i += 2
        elif sys.argv[i] == "--no-screenshots":
            extract_screenshots_flag = False
            i += 1
        elif sys.argv[i] == "--smart-screenshots":
            screenshot_mode = "smart"
            i += 1
        elif sys.argv[i] == "--screenshot-mode" and i + 1 < len(sys.argv):
            screenshot_mode = sys.argv[i + 1]
            if screenshot_mode not in ["periodic", "smart", "transcript", "both"]:
                print(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ä–µ–∂–∏–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {screenshot_mode}")
                sys.exit(1)
            i += 2
        elif sys.argv[i] == "--clean-transcript":
            clean_transcript = True
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–ª–µ–¥—É—é—â–∏–π –∞—Ä–≥—É–º–µ–Ω—Ç –∏ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ–Ω —á–∏—Å–ª–æ–º
            if i + 1 < len(sys.argv) and sys.argv[i + 1].isdigit():
                chunk_duration = int(sys.argv[i + 1])
                i += 2
            else:
                i += 1
        elif sys.argv[i] == "--basic-mode":
            basic_mode = True
            i += 1
        elif sys.argv[i] == "--output" and i + 1 < len(sys.argv):
            output_dir = sys.argv[i + 1]
            i += 2
        elif sys.argv[i] == "--clear-cache":
            clear_cache = True
            i += 1
        elif sys.argv[i] == "--force-refresh":
            force_refresh = True
            i += 1
        elif sys.argv[i] == "--cache-status":
            cache_status_only = True
            i += 1
        elif sys.argv[i] == "--test-first-10min":
            test_first_10min = True
            i += 1
        else:
            i += 1
    
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("‚ùå API –∫–ª—é—á OpenAI –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–î–ª—è —Ä–∞–±–æ—Ç—ã –∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–æ–±–∞–≤—å—Ç–µ OPENAI_API_KEY –≤ .env —Ñ–∞–π–ª")
        print("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º...")
        basic_mode = True
        if screenshot_mode in ["smart", "transcript"]:
            screenshot_mode = "periodic"  # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º –±–µ–∑ API
    
    if not os.path.exists(video_path):
        print(f"–û—à–∏–±–∫–∞: –í–∏–¥–µ–æ—Ñ–∞–π–ª {video_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        sys.exit(1)
    
    video_name = os.path.splitext(os.path.basename(video_path))[0]
    
    # –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
    if basic_mode:
        print(f"üìä –ë–ê–ó–û–í–´–ô —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ: {video_name}")
        chronological_mode = False
    else:
        print(f"ü§ñ –ê–ì–ï–ù–¢–ù–´–ô —Ä–µ–∂–∏–º –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ: {video_name}")
        print("‚ú® –í–∫–ª—é—á–µ–Ω –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π")
        chronological_mode = True  # –ê–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º –≤—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    
    print(f"üé¨ –†–µ–∂–∏–º —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤: {screenshot_mode}")
    if clean_transcript:
        print(f"üìù –ß–ò–°–¢–´–ô —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: –±–ª–æ–∫–∏ –ø–æ {chunk_duration} —Å–µ–∫—É–Ω–¥ (–ë–ï–ó –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫)")
    if test_first_10min:
        print("‚è±Ô∏è  –¢–ï–°–¢–û–í–´–ô —Ä–µ–∂–∏–º: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –º–∏–Ω—É—Ç")

    try:
        # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞
        cache_manager = CacheManager()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∫—ç—à–∞
        if clear_cache:
            print("üßπ –û—á–∏—â–∞–µ–º –∫—ç—à –¥–ª—è –≤–∏–¥–µ–æ...")
            cache_manager.clear_cache(video_path)
            print("‚úÖ –ö—ç—à –æ—á–∏—â–µ–Ω")
            return
        
        if cache_status_only:
            cache_manager.print_cache_status(video_path)
            return
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –∫—ç—à–∞
        cache_manager.print_cache_status(video_path)
        
        # –ï—Å–ª–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ, –≤—Ä–µ–º–µ–Ω–Ω–æ "–æ—Ç–∫–ª—é—á–∞–µ–º" –∫—ç—à
        if force_refresh:
            print("üîÑ –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ - –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫—ç—à")
            cache_manager = None
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—É–¥–∏–æ (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫—ç—à–∞)
        audio_path = extract_audio_from_video(video_path, cache_manager=cache_manager)
        if not audio_path:
            print("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∞—É–¥–∏–æ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
            sys.exit(1)
        
        # –°–æ–∑–¥–∞–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å –ø–æ–º–æ—â—å—é Whisper (—Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∫—ç—à–∞)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞ Apple Silicon –ª–∏ –º—ã
        import platform
        use_mlx = platform.system() == "Darwin" and platform.machine() == "arm64"
        
        if clean_transcript:
            print(f"üìù –°–æ–∑–¥–∞–Ω–∏–µ –ß–ò–°–¢–û–ì–û —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –±–ª–æ–∫–∞–º–∏ –ø–æ {chunk_duration} —Å–µ–∫—É–Ω–¥...")
            full_transcript = create_clean_transcript_with_whisper(
                audio_path, whisper_model, video_path=video_path, 
                cache_manager=cache_manager, chunk_duration=chunk_duration
            )
            transcript_segments = None  # –ù–µ—Ç —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –≤ —á–∏—Å—Ç–æ–º —Ä–µ–∂–∏–º–µ
            if not full_transcript:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —á–∏—Å—Ç—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
                sys.exit(1)
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º MLX Whisper –Ω–∞ Apple Silicon
            if use_mlx:
                print("üçé –û–±–Ω–∞—Ä—É–∂–µ–Ω Apple Silicon - –∏—Å–ø–æ–ª—å–∑—É–µ–º MLX Whisper —Å GPU —É—Å–∫–æ—Ä–µ–Ω–∏–µ–º")
                transcript_segments, full_transcript = create_transcript_with_mlx_whisper(
                    audio_path, whisper_model, video_path=video_path, cache_manager=cache_manager
                )
            else:
                transcript_segments, full_transcript = create_transcript_with_whisper(
                    audio_path, whisper_model, video_path=video_path, cache_manager=cache_manager
                )
            
            if not full_transcript:
                print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã.")
                sys.exit(1)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–º–∏ 10 –º–∏–Ω—É—Ç–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        if test_first_10min and transcript_segments:
            print("‚è±Ô∏è  –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã–º–∏ 10 –º–∏–Ω—É—Ç–∞–º–∏...")
            original_segments_count = len(transcript_segments)
            transcript_segments = [s for s in transcript_segments if s['start'] <= 600]  # 10 –º–∏–Ω—É—Ç = 600 —Å–µ–∫
            
            # –û–±—Ä–µ–∑–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Ç–æ–∂–µ
            if transcript_segments:
                last_segment_end = transcript_segments[-1]['start'] + transcript_segments[-1].get('duration', 0)
                # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω—É—é –ø–æ–∑–∏—Ü–∏—é –≤ –ø–æ–ª–Ω–æ–º —Ç–µ–∫—Å—Ç–µ
                chars_per_second = len(full_transcript) / (last_segment_end if last_segment_end > 0 else 1)
                cut_position = int(chars_per_second * 600)
                full_transcript = full_transcript[:cut_position] + "\n\n[–ê–Ω–∞–ª–∏–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –ø–µ—Ä–≤—ã–º–∏ 10 –º–∏–Ω—É—Ç–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è]"
            
            print(f"üìä –°–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {original_segments_count}")
            print(f"üìä –°–µ–≥–º–µ–Ω—Ç–æ–≤ –ø–æ—Å–ª–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {len(transcript_segments)}")
        elif test_first_10min and clean_transcript:
            print("‚è±Ô∏è  –í —Ä–µ–∂–∏–º–µ —á–∏—Å—Ç–æ–≥–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ 10 –º–∏–Ω—É—Ç –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è")
            print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --chunk-duration –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–º–µ—Ä–∞ –±–ª–æ–∫–æ–≤")
        
        print(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞–Ω. –î–ª–∏–Ω–∞: {len(full_transcript)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        screenshots = []
        if extract_screenshots_flag:
            screenshots_dir = os.path.join(output_dir, f"{video_name}_screenshots")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
            cached_screenshots = cache_manager.get_cached_screenshots(video_path, screenshot_mode)
            if cached_screenshots:
                print(f"üì∏ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∫—Ä–∏–Ω—à–æ—Ç—ã —Ä–µ–∂–∏–º–∞ '{screenshot_mode}'")
                screenshots = [(shot['path'], shot['timestamp'], shot['description'], shot['reason']) 
                              for shot in cached_screenshots]
            else:
                if screenshot_mode == "transcript":
                    print("\nüß† –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤...")
                    extractor = SmartTranscriptExtractor(api_key)
                    screenshots = extractor.extract_screenshots(
                        video_path, screenshots_dir, transcript_segments
                    )
                
                elif screenshot_mode == "smart":
                    print("\nü§ñ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ò–ò –¥–ª—è –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤...")
                    extractor = AdaptiveScreenshotExtractor(api_key)
                    screenshots = extractor.extract_screenshots(
                        video_path, screenshots_dir, transcript_segments
                    )
                
                elif screenshot_mode == "periodic":
                    print(f"\nüì∏ –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –∫–∞–∂–¥—ã–µ {screenshot_interval} —Å–µ–∫—É–Ω–¥...")
                    screenshots = extract_screenshots_traditional(
                        video_path, screenshots_dir, screenshot_interval, api_key
                    )
                
                elif screenshot_mode == "both":
                    print("\nüî¨ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –∞–Ω–∞–ª–∏–∑ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ + –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ...")
                    # –°–Ω–∞—á–∞–ª–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç
                    transcript_extractor = SmartTranscriptExtractor(api_key)
                    transcript_screenshots = transcript_extractor.extract_screenshots(
                        video_path, screenshots_dir, transcript_segments
                    )
                    
                    # –ó–∞—Ç–µ–º –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ (—Ä–µ–∂–µ)
                    periodic_screenshots = extract_screenshots_traditional(
                        video_path, screenshots_dir, screenshot_interval * 2, api_key  # –†–µ–∂–µ –¥–ª—è –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
                    )
                    
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º, –∏–∑–±–µ–≥–∞—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                    screenshots = transcript_screenshots
                    for p_shot in periodic_screenshots:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ—Ç –ª–∏ –±–ª–∏–∑–∫–æ–≥–æ —É–º–Ω–æ–≥–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
                        is_duplicate = any(
                            abs(s[1] - p_shot[1]) < 10  # –í –ø—Ä–µ–¥–µ–ª–∞—Ö 10 —Å–µ–∫—É–Ω–¥
                            for s in transcript_screenshots
                        )
                        if not is_duplicate:
                            screenshots.append(p_shot)
                    
                    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    screenshots.sort(key=lambda x: x[1])
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –≤ –∫—ç—à –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                if screenshots:
                    cache_manager.save_screenshots_cache(video_path, screenshots, screenshot_mode)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        analysis = None
        if api_key:
            print("\nüìä –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é GPT...")
            analysis = analyze_content_with_gpt(
                full_transcript, api_key, video_name, screenshots, 
                video_path=video_path, cache_manager=cache_manager
            )
        
        # ü§ñ –ê–ì–ï–ù–¢–ù–´–ô –•–†–û–ù–û–õ–û–ì–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ –∞–≥–µ–Ω—Ç–Ω–æ–º —Ä–µ–∂–∏–º–µ)
        if chronological_mode and CHRONOLOGICAL_AVAILABLE and api_key:
            print("\nü§ñ –ó–∞–ø—É—Å–∫–∞–µ–º –ê–ì–ï–ù–¢–ù–´–ô —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑...")
            print("‚ú® –î–µ—Ç–∞–ª—å–Ω–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–º—ã—Å–ª–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π")
            
            # –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤–∏–¥–µ–æ –¥–ª—è –∞–≥–µ–Ω—Ç–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
            video_context = {
                'meeting_type': 'technical_discussion',  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –≤—Å—Ç—Ä–µ—á—É
                'main_topics': ['technical_details', 'equipment', 'data_processing'],
                'visual_content_probability': 0.8,  # –í—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                'use_agent_mode': True,  # –§–ª–∞–≥ –¥–ª—è –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
                'preserve_details': True,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –≤—Å–µ –¥–µ—Ç–∞–ª–∏
                'test_mode': test_first_10min  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            }
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
            screenshots_formatted = []
            if screenshots:
                if isinstance(screenshots[0], dict):
                    # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–∑ AdaptiveScreenshotExtractor
                    screenshots_formatted = [
                        (shot['path'], shot['timestamp'], shot.get('description'), shot.get('decision', {}).get('reason', 'screenshot'))
                        for shot in screenshots
                    ]
                else:
                    # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                    screenshots_formatted = screenshots
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç—ã –ø–µ—Ä–≤—ã–º–∏ 10 –º–∏–Ω—É—Ç–∞–º–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
                if test_first_10min:
                    screenshots_formatted = [s for s in screenshots_formatted if s[1] <= 600]
                    print(f"üì∏ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(screenshots_formatted)}")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–≥–µ–Ω—Ç–Ω—É—é —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
            processor = ChronologicalTranscriptProcessor(api_key)
            chronological_data = processor.process_video_meeting(
                transcript_segments, screenshots_formatted, video_context
            )
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            chron_md, chron_json = save_chronological_results(video_name, chronological_data, output_dir)
            
            print(f"\nüéâ –ê–ì–ï–ù–¢–ù–´–ô –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
            print(f"  üé¨ –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç: {chron_md}")
            print(f"  üìã –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: {chron_json}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∞–≥–µ–Ω—Ç–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π
            timeline = chronological_data.get('timeline', [])
            corrected_count = sum(1 for event in timeline 
                                if event.type == 'transcript' and 
                                event.content.get('corrected_text') != event.content.get('text'))
            technical_details_count = sum(1 for event in timeline 
                                        if event.type == 'transcript' and 
                                        event.content.get('technical_details'))
            screen_references_count = sum(1 for event in timeline 
                                        if event.type == 'transcript' and 
                                        event.content.get('screen_references'))
            
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ê–ì–ï–ù–¢–ù–´–• –£–õ–£–ß–®–ï–ù–ò–ô:")
            print(f"  ‚úèÔ∏è  Whisper –∫–æ—Ä—Ä–µ–∫—Ü–∏–π: {corrected_count}")
            print(f"  ‚öôÔ∏è  –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π: {technical_details_count}")
            print(f"  üì∫ –°—Å—ã–ª–æ–∫ –Ω–∞ —ç–∫—Ä–∞–Ω: {screen_references_count}")
        
        elif chronological_mode and not CHRONOLOGICAL_AVAILABLE:
            print("‚ö†Ô∏è  –ê–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ chronological_transcript_processor.py")
            print("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º...")
            chronological_mode = False
        
        elif chronological_mode and not api_key:
            print("‚ö†Ô∏è  –î–ª—è –∞–≥–µ–Ω—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –Ω—É–∂–µ–Ω API –∫–ª—é—á OpenAI")
            print("–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –±–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º...")
            chronological_mode = False
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—Ç—å
        if chronological_mode and 'chron_md' in locals():
            # –ê–≥–µ–Ω—Ç–Ω—ã–π —Ä–µ–∂–∏–º - –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            md_file = chron_md
            json_file = chron_json
            mode_description = "ü§ñ –ê–ì–ï–ù–¢–ù–´–ô"
        else:
            # –ë–∞–∑–æ–≤—ã–π —Ä–µ–∂–∏–º - –æ–±—ã—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            md_file, json_file = save_results(video_name, transcript_segments, full_transcript, analysis, screenshots, output_dir)
            mode_description = "üìä –ë–ê–ó–û–í–´–ô"
        
        print(f"\nüéâ {mode_description} –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"  üìÑ –û—Ç—á–µ—Ç: {md_file}")
        print(f"  üìã –î–∞–Ω–Ω—ã–µ: {json_file}")
        
        if test_first_10min:
            print(f"  ‚è±Ô∏è  –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –ø–µ—Ä–≤—ã–µ 10 –º–∏–Ω—É—Ç –≤–∏–¥–µ–æ")
        
        if screenshots:
            screenshot_count = len(screenshots)
            if test_first_10min:
                screenshot_count = len([s for s in screenshots if s[1] <= 600])
            
            print(f"  üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç—ã: {screenshot_count} —Ñ–∞–π–ª–æ–≤")
            if screenshot_mode == "transcript":
                print(f"     üß† –ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞ –Ω–∞–π–¥–µ–Ω–æ {screenshot_count} –∫–ª—é—á–µ–≤—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤")
            elif screenshot_mode == "smart":
                ai_count = len([s for s in screenshots if s[3] != "periodic"])
                print(f"     ü§ñ –ò–ò –æ–ø—Ä–µ–¥–µ–ª–∏–ª {ai_count} –≤–∞–∂–Ω—ã—Ö –º–æ–º–µ–Ω—Ç–æ–≤")
            elif screenshot_mode == "both":
                transcript_count = len([s for s in screenshots if getattr(s, 'method', 'transcript') == 'transcript'])
                periodic_count = len([s for s in screenshots if s[3] == "periodic"])
                print(f"     üß† –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç: {transcript_count}, üì∏ –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ: {periodic_count}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        metadata = {
            'whisper_model': whisper_model,
            'screenshot_mode': screenshot_mode,
            'chronological_mode': chronological_mode,
            'clean_transcript_mode': clean_transcript,
            'chunk_duration': chunk_duration if clean_transcript else None,
            'transcript_length': len(full_transcript),
            'segments_count': len(transcript_segments) if transcript_segments else 0,
            'screenshots_count': len(screenshots) if screenshots else 0
        }
        cache_manager.save_metadata(video_path, metadata)
        
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª (–ù–ï –∏–∑ –∫—ç—à–∞)
        if audio_path and os.path.exists(audio_path) and not audio_path.startswith(cache_manager.cache_dir):
            os.remove(audio_path)
            print("\nüßπ –í—Ä–µ–º–µ–Ω–Ω—ã–π –∞—É–¥–∏–æ—Ñ–∞–π–ª —É–¥–∞–ª–µ–Ω")
        
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
